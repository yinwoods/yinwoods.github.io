<!DOCTYPE html><html lang="zh-CN"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta name="author" content="yinwoods,yinwoods#163.com"><title>IO模式和IO多路复用 · yinwoods</title><meta name="description" content="现在操作系统都采用虚拟寻址，处理器先产生一个虚拟地址，通过地址翻译成物理地址（内存的地址），再通过总线的传递，最后处理器拿到某个物理地址返回的字节。
对32位操作系统而言，它的寻址空间（虚拟存储空间）为4G（2的32次方）。
核空间：在liunx中，将最高的1G字节（从虚拟地址0xC0000000到"><meta name="keywords" content="Hexo,Linux,Python"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="renderer" content="webkit"><link rel="short icon" href="/images/favicon.png" type="image/x-icon"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/blog_basic.css"><link rel="stylesheet" href="/css/font-awesome.min.css"><link rel="alternate" type="application/atom+xml" title="ATOM 1.0" href="/atom.xml"></head><body><div class="sidebar animated fadeInDown"><div class="logo-title"><div class="title"><img src="/images/logo@2x.png" style="width:127px;"><h3 title=""><a href="/">yinwoods</a></h3><div class="description"><p>To Be A Better Man!😈</p></div></div></div><ul class="social-links"><li><a href="http://weibo.com/yinwoods"><i class="fa fa-weibo"></i></a></li><li><a href="http://facebook.com/yinwoods"><i class="fa fa-facebook"></i></a></li><li><a href="http://github.com/yinwoods"><i class="fa fa-github"></i></a></li></ul><div class="footer"><a target="_blank" href="/"><span>Theme by </span></a><a href="https://www.caicai.me"> CaiCai </a><span>&</span><a href="https://github.com/Ben02/hexo-theme-Anatole"> Ben</a><div class="by_farbox"><a href="https://hexo.io/zh-cn/" target="_blank">Proudly published with Hexo&#65281;</a></div></div></div><div class="main"><div class="page-top animated fadeInDown"><div class="nav"><li><a href="/">首页</a></li><li><a href="/archives">归档</a></li><li><a href="/links">友链</a></li><li><a href="/about">关于</a></li></div><div class="information"><div class="back_btn"><li><a onclick="window.history.go(-1)" class="fa fa-chevron-left"> </a></li></div><div class="avatar"><img src="/images/favicon.png"></div></div></div><div class="autopagerize_page_element"><div class="content"><div class="post-page"><div class="post animated fadeInDown"><div class="post-title"><h3><a>IO模式和IO多路复用</a></h3></div><div class="post-content"><p>现在操作系统都采用虚拟寻址，处理器先产生一个虚拟地址，通过地址翻译成物理地址（内存的地址），再通过总线的传递，最后处理器拿到某个物理地址返回的字节。</p>
<p>对32位操作系统而言，它的寻址空间（虚拟存储空间）为4G（2的32次方）。</p>
<p>核空间：在liunx中，将最高的1G字节（从虚拟地址0xC0000000到0xFFFFFFFF），供内核使用，称为“内核空间”。</p>
<p>用户空间: 在liunx中，将较低的3G字节（从虚拟地址 0x00000000到0xBFFFFFFF），供各个进程使用，称为“用户空间）。</p>
<p>内核态：当一个任务（进程）执行系统调用而陷入内核代码中执行时，我们就称进程处于内核运行态</p>
<p>用户态：每个进程都有自己的内核栈。当进程在执行用户自己的代码时，则称其处于用户运行态（用户态）</p>
<p>因为每个进程可以通过系统调用进入内核，因此，Linux内核由系统 内的所有进程共享。于是，从具体进程的角度来看，每个进程可以拥有4G字节的虚拟空间。</p>
<ul>
<li><p>进程寻址空间0~4G</p>
</li>
<li><p>进程在用户态只能访问0~3G，只有进入内核态才能访问3G~4G</p>
</li>
<li><p>进程通过系统调用进入内核态</p>
</li>
<li>每个进程虚拟空间的3G~4G部分是相同的</li>
</ul>
<h4 id="进程上下文切换（进程切换）"><a href="#进程上下文切换（进程切换）" class="headerlink" title="进程上下文切换（进程切换）"></a>进程上下文切换（进程切换）</h4><p>为了控制进程的执行，内核必须有能力挂起正在CPU上运行的进程，并恢复以前挂起的某个进程的执行。这种行为被称为进程切换（也叫调度）。因此可以说，任何进程都是在操作系统内核的支持下运行的，是与内核紧密相关的。</p>
<p>从一个进程的运行转到另一个进程上运行，这个过程中经过下面这些变化：</p>
<ol>
<li><p>保存当前进程A的上下文。 上下文就是内核再次唤醒当前进程时所需要的状态，由一些对象（程序计数器、状态寄存器、用户栈等各种内核数据结构）的值组成。 这些值包括描绘地址空间的页表、包含进程相关信息的进程表、文件表等。</p>
</li>
<li><p>切换页全局目录以安装一个新的地址空间。</p>
</li>
<li><p>恢复进程B的上下文。</p>
</li>
</ol>
<p>可以理解成一个比较耗资源的过程。</p>
<h4 id="直接I-O和缓存I-O"><a href="#直接I-O和缓存I-O" class="headerlink" title="直接I/O和缓存I/O"></a>直接I/O和缓存I/O</h4><p>缓存 I/O 又被称作标准 I/O，大多数文件系统的默认 I/O 操作都是缓存 I/O。在 Linux 的缓存 I/O 机制中，以write为例，数据会先被拷贝进程缓冲区，在拷贝到操作系统内核的缓冲区中，然后才会写到存储设备中。<br><img src="https://l.ruby-china.org/photo/2018/d410db1c-f699-4122-8c4d-e28a348d31dd.png!large" alt="1.3"></p>
<h2 id="IO模式"><a href="#IO模式" class="headerlink" title="IO模式"></a>IO模式</h2><p>对于一次IO访问（这回以read举例），数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓冲区拷贝到应用程序的缓冲区，最后交给进程。所以说，当一个read操作发生时，它会经历两个阶段：</p>
<ul>
<li><ol>
<li>等待数据准备 (Waiting for the data to be ready)</li>
</ol>
</li>
<li><ol>
<li>将数据从内核拷贝到进程中 (Copying the data from the kernel to the process)</li>
</ol>
</li>
</ul>
<p>正式因为这两个阶段，linux系统产生了下面五种网络模式的方案：</p>
<ul>
<li>– 阻塞 I/O（blocking IO）</li>
<li>– 非阻塞 I/O（nonblocking IO）</li>
<li>– I/O 多路复用（ IO multiplexing）</li>
<li>– 信号驱动 I/O（ signal driven IO）</li>
<li>– 异步 I/O（asynchronous IO）</li>
</ul>
<h4 id="block-I-O模型（阻塞I-O）"><a href="#block-I-O模型（阻塞I-O）" class="headerlink" title="block I/O模型（阻塞I/O）"></a>block I/O模型（阻塞I/O）</h4><p>read为例：<br><img src="https://l.ruby-china.org/photo/2018/56b3cedc-cd0e-4d54-a001-28004acc71ad.jpg!large" alt="block IO"></p>
<p>（1）进程发起read，进行recvfrom系统调用；</p>
<p>（2）内核开始第一阶段，准备数据（从磁盘拷贝到缓冲区），进程请求的数据并不是一下就能准备好；准备数据是要消耗时间的；</p>
<p>（3）与此同时，进程阻塞（进程是自己选择阻塞与否），等待数据ing；</p>
<p>（4）直到数据从内核拷贝到了用户空间，内核返回结果，进程解除阻塞。</p>
<p>也就是说，内核准备数据和数据从内核拷贝到进程内存地址这两个过程都是阻塞的。</p>
<h4 id="non-block（非阻塞I-O模型）"><a href="#non-block（非阻塞I-O模型）" class="headerlink" title="non-block（非阻塞I/O模型）"></a>non-block（非阻塞I/O模型）</h4><p>可以通过设置socket使其变为non-blocking。当对一个non-blocking socket执行读操作时，流程是这个样子：<br><img src="https://l.ruby-china.org/photo/2018/77179aa5-7754-4822-8ab4-903566840175.jpg!large" alt="non-block IO"></p>
<p>（1）当用户进程发出read操作时，如果kernel中的数据还没有准备好；</p>
<p>（2）那么它并不会block用户进程，而是立刻返回一个error，从用户进程角度讲 ，它发起一个read操作后，并不需要等待，而是马上就得到了一个结果；</p>
<p>（3）用户进程判断结果是一个error时，它就知道数据还没有准备好，于是它可以再次发送read操作。一旦kernel中的数据准备好了，并且又再次收到了用户进程的system call；</p>
<p>（4）那么它马上就将数据拷贝到了用户内存，然后返回。</p>
<p>所以，nonblocking IO的特点是用户进程在内核准备数据的阶段需要不断的主动询问数据好了没有。</p>
<h4 id="I-O多路复用"><a href="#I-O多路复用" class="headerlink" title="I/O多路复用"></a>I/O多路复用</h4><p>I/O多路复用实际上就是用select, poll, epoll监听多个io对象，对一个IO端口，两次调用，两次返回，比阻塞IO并没有什么优越性；关键是能实现同时对多个IO端口进行监听；当io对象有变化（有数据）的时候就通知用户进程。现在先来看下I/O多路复用的流程：<br><img src="https://l.ruby-china.org/photo/2018/6b727e99-b45e-4104-ba1d-1dd2dd281e52.jpg!large" alt="I/O多路复用"><br>（1）当用户进程调用了select，那么整个进程会被block；</p>
<p>（2）而同时，kernel会“监视”所有select负责的socket；</p>
<p>（3）当任何一个socket中的数据准备好了，select就会返回；</p>
<p>（4）这个时候用户进程再调用read操作，将数据从kernel拷贝到用户进程。</p>
<p>所以，I/O 多路复用的特点是通过一种机制一个进程能同时等待多个文件描述符，而这些文件描述符（套接字描述符）其中的任意一个进入读就绪状态，select()函数就可以返回。</p>
<p>这个图和blocking IO的图其实并没有太大的不同，事实上，还更差一些。因为这里需要使用两个system call (select 和 recvfrom)，而blocking IO只调用了一个system call (recvfrom)。 但是，用select的优势在于它可以同时处理多个connection。</p>
<p>所以，如果处理的连接数不是很高的话，使用select/epoll的web server不一定比使用多线程 + 阻塞 IO的web server性能更好，可能延迟还更大。</p>
<p>select/epoll的优势并不是对于单个连接能处理得更快，而是在于能处理更多的连接。</p>
<p>在IO multiplexing Model中，实际中，对于每一个socket，一般都设置成为non-blocking，但是，如上图所示，整个用户的process其实是一直被block的。只不过process是被select这个函数block，而不是被socket IO给block。</p>
<h4 id="信号驱动I-O模型"><a href="#信号驱动I-O模型" class="headerlink" title="信号驱动I/O模型"></a>信号驱动I/O模型</h4><p><img src="https://l.ruby-china.org/photo/2018/c672dd70-c22a-42a6-a798-0c12aa7bf765.png!large" alt="sigio"></p>
<p>我们首先开启套接口的信号驱动I/O功能，并通过sigaction系统调用安装一个信号处理函数。该系统调用立即返回，我们的进程继续工作，也就是说它没有被阻塞。当数据报准备好读取时，内核就为该进程产生一个SIGIO信号。我们随后既可以在信号处理函数中调用recvfrom读取数据报，并通知主循环数据已准备好待处理，也可以立即通知主循环，让它读取数据报。</p>
<p>无论如何处理SIGIO信号，这种模型的优势在于等待数据报到达期间，进程不被阻塞。主循环可以继续执行，只要不时等待来自信号处理函数的通知：既可以是数据已准备好被处理，也可以是数据报已准备好被读取。</p>
<h4 id="asynchronous-I-O（异步-I-O）"><a href="#asynchronous-I-O（异步-I-O）" class="headerlink" title="asynchronous I/O（异步 I/O）"></a>asynchronous I/O（异步 I/O）</h4><p>异步I/O（asynchronous I/O）由POSIX规范定义。一般地说，这些函数的工作机制是：告知内核启动某个操作，并让内核在整个操作（包括将数据从内核拷贝到我们自己的缓冲区）完成后通知我们。这种模型与信号驱动模型的主要区别在于：信号驱动I/O是由内核通知我们何时启动一个I/O操作，而异步I/O模型是由内核通知我们I/O操作何时完成。</p>
<p><img src="https://l.ruby-china.org/photo/2018/9ad0c25d-72e9-4a2d-8182-5cea6dc73b28.jpg!large" alt="asyncio"></p>
<p>我们调用aio<em>read函数（POSIX异步I/O函数以aio</em>或lio_开头），给内核传递描述字、缓冲区指针、缓冲区大小（与read相同的三个参数）、文件偏移（与lseek类似），并告诉内核当整个操作完成时如何通知我们。该系统调用立即返回，在等待I/O完成期间，我们的进程不被阻塞。</p>
<p>（1）用户进程发起read操作之后，立刻就可以开始去做其它的事。</p>
<p>（2）而另一方面，从kernel的角度，当它受到一个asynchronous read之后，首先它会立刻返回，所以不会对用户进程产生任何block。</p>
<p>（3）然后，kernel会等待数据准备完成，然后将数据拷贝到用户内存，当这一切都完成之后，kernel会给用户进程发送一个signal，告诉它read操作完成了。</p>
<h2 id="select-poll-epoll"><a href="#select-poll-epoll" class="headerlink" title="select/poll/epoll"></a>select/poll/epoll</h2><p>在服务器端，每次通过accept系统调用接收客户端请求，建立连接，接着服务器端会获取代表这个连接的文件描述符（Linux下socket也被视为文件），并处理这个文件描述符上的相关请求。当与服务器端连接的大量客户端同时请求时，服务端需要能够感知到请求的到来并及时处理。一个很简单的思路是使用CPU轮询已建立连接的文件描述符上是否有新的请求到来，类似如下的代码：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span> descriptor <span class="keyword">in</span> open_connections:</div><div class="line">    <span class="keyword">if</span> has_new_input(descriptor):</div><div class="line">        process_input(descriptor)</div></pre></td></tr></table></figure></p>
<p>这种方法理论上是可行的，但是当大量连接中只有少量是活跃的连接时，这无疑会浪费很多CPU时间，在Linux下，与其在服务端对这些文件描述符做轮询，不如把文件描述符交给内核，让它负责告诉服务端哪个文件描述符上有新的请求。让Linux处理大量文件描户符的操作其实就是I/O多路复用，I/O多路复用的本质就是用select/poll/epoll，去监听多个socket文件描述符，如果其中的socket文件描述符有变化，只要有变化，服务器进程就知道了。</p>
<p>在任意unix机器上，select和poll都是可用的，epoll则只能够在Linux上使用。select和poll的工作方式如下：</p>
<ol>
<li>将多个文件描述符传递给select/poll</li>
<li>select/poll会在任一文件描述符有新的请求到来时告知服务端进程</li>
</ol>
<p>需要注意的是select和poll的源码几乎是相同的，不同的是select支持的操作不如poll支持的丰富，如在文件描述符有新的请求到来时，select只会返回<code>有新的输入</code>、<code>有新的输出</code>或<code>有新的错误</code>；而poll则支持<code>POLLRDNORM | POLLRDBAND | POLLIN | POLLHUP | POLLERR</code>，select会将poll所支持的多种输出统一转换为一种输出：<code>可写</code></p>
<p>当文件描述符数量较少时，poll的性能表现也会好于select，区别可以从二者的函数声明中看出：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">int ppoll(struct pollfd *fds, nfds_t nfds,</div><div class="line">          const struct timespec *tmo_p, const sigset_t</div><div class="line">          *sigmask)`</div><div class="line"></div><div class="line">int pselect(int nfds, fd_set *readfds, fd_set *writefds,</div><div class="line">            fd_set *exceptfds, const struct timespec *timeout,</div><div class="line">            const sigset_t *sigmask);</div></pre></td></tr></table></figure>
<p>当使用poll时，可以传递对应的文件描述符集合，从而使其只关注对应的文件描述符；而select则仍会遍历所有的文件描述符，但仅对遍历过程中满足sigmask的文件描述符进行监听；如当需要监听1、3、8、19的文件描述符时，可以在<code>fds</code>中指明1、3、8、19；而使用select时，则会遍历从0到19的所有描述符，再使用sigmask判断每个文件描述符是否是需要监听的。</p>
<p>另外，select是不断轮询去监听的socket，socket个数有限制，一般为1024个；poll还是采用轮询方式监听，只不过没有个数限制；</p>
<p>nodejs使用epoll模型的原因是：epoll并不是采用轮询方式去监听了，而是当socket有变化时通过回调的方式主动告知用户进程。能够有效提升CPU利用率。</p>
<p>性能对比：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="meta"># operations  |  poll  |  select   | epoll</span></div><div class="line"><span class="number">10</span>            |   <span class="number">0.61</span> |    <span class="number">0.73</span>   | <span class="number">0.41</span></div><div class="line"><span class="number">100</span>           |   <span class="number">2.9</span>  |    <span class="number">3.0</span>    | <span class="number">0.42</span></div><div class="line"><span class="number">1000</span>          |  <span class="number">35</span>    |   <span class="number">35</span>      | <span class="number">0.53</span></div><div class="line"><span class="number">10000</span>         | <span class="number">990</span>    |  <span class="number">930</span>      | <span class="number">0.66</span></div></pre></td></tr></table></figure>
<p><strong>需要注意的是：epoll并不是在所有的应用场景都会比select和poll高很多。尤其是当活动连接比较多的时候，回调函数被触发得过于频繁的时候，epoll的效率也会受到显著影响！所以，epoll特别适用于连接数量多，但活动连接较少的情况。</strong></p>
<h3 id="LT（水平触发）和ET（边缘出发）"><a href="#LT（水平触发）和ET（边缘出发）" class="headerlink" title="LT（水平触发）和ET（边缘出发）"></a>LT（水平触发）和ET（边缘出发）</h3><p>epoll对文件描述符的操作有两种模式：LT（level trigger）和ET（edge trigger）。LT模式是默认模式，LT模式与ET模式的区别如下：<br>　　LT模式：当epoll_wait检测到描述符事件发生并将此事件通知应用程序，应用程序可以不立即处理该事件。下次调用epoll_wait时，会再次响应应用程序并通知此事件。<br>　　ET模式：当epoll_wait检测到描述符事件发生并将此事件通知应用程序，应用程序必须立即处理该事件。如果不处理，下次调用epoll_wait时，不会再次响应应用程序并通知此事件。</p>
<p>LT：水平触发，效率会低于ET触发，尤其在大并发，大流量的情况下。但是LT对代码编写要求比较低，不容易出现问题。LT模式服务编写上的表现是：只要有数据没有被获取，内核就不断通知你，因此不用担心事件丢失的情况。<br>ET：边缘触发，效率非常高，在并发，大流量的情况下，会比LT少很多epoll的系统调用，因此效率高。但是对编程要求高，需要细致的处理每个请求，否则容易发生丢失事件的情况。</p>
<p>ET模式在很大程度上减少了epoll事件被重复触发的次数，因此效率要比LT模式高。epoll工作在ET模式的时候，必须使用非阻塞套接口，以避免由于一个文件句柄的阻塞读/阻塞写操作把处理多个文件描述符的任务饿死。</p>
<h4 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h4><p><a href="https://ruby-china.org/topics/35472" target="_blank" rel="external">IO 模式和 IO 多路复用 · Ruby China</a><br><a href="https://idea.popcount.org/2017-01-06-select-is-fundamentally-broken/" target="_blank" rel="external">Select is fundamentally broken —    Idea of the day</a><br><a href="https://jvns.ca/blog/2017/06/03/async-io-on-linux--select--poll--and-epoll/" target="_blank" rel="external">Async IO on Linux: select, poll, and epoll - Julia Evans</a></p>
</div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-sun-o"></i><span class="date">2018-06-02</span><i class="fa fa-comment-o"></i><a href="/2018/06/02/IO模式和IO多路复用/#comments">评论</a><i class="fa fa-tag"></i><a href="/categories/coding/" title="coding" class="tag">coding </a><a href="/tags/Linux-操作系统-服务器编程/" title="Linux 操作系统 服务器编程" class="tag">Linux 操作系统 服务器编程 </a></div></div></div></div><div class="share"><div class="evernote"><a href="javascript:(function(){EN_CLIP_HOST='http://www.evernote.com';try{var%20x=document.createElement('SCRIPT');x.type='text/javascript';x.src=EN_CLIP_HOST+'/public/bookmarkClipper.js?'+(new%20Date().getTime()/100000);document.getElementsByTagName('head')[0].appendChild(x);}catch(e){location.href=EN_CLIP_HOST+'/clip.action?url='+encodeURIComponent(location.href)+'&amp;title='+encodeURIComponent(document.title);}})();" ref="nofollow" target="_blank" class="fa fa-bookmark"></a></div><div class="weibo"><a href="javascript:void((function(s,d,e){try{}catch(e){}var f='http://service.weibo.com/share/share.php?',u=d.location.href,p=['url=',e(u),'&amp;title=',e(d.title),'&amp;appkey=2924220432'].join('');function a(){if(!window.open([f,p].join(''),'mb',['toolbar=0,status=0,resizable=1,width=620,height=450,left=',(s.width-620)/2,',top=',(s.height-450)/2].join('')))u.href=[f,p].join('');};if(/Firefox/.test(navigator.userAgent)){setTimeout(a,0)}else{a()}})(screen,document,encodeURIComponent));" class="fa fa-weibo"></a></div><div class="twitter"><a href="http://twitter.com/home?status=,http://blog.yinwoods.work/2018/06/02/IO模式和IO多路复用/,yinwoods,IO模式和IO多路复用,;" class="fa fa-twitter"></a></div></div><div class="pagination"><ul class="clearfix"><li class="next pagbuttons"><a role="navigation" href="/2017/12/30/配置不同局域网ssh互联/" title="配置不同局域网ssh互联" class="btn">下一篇</a></li></ul></div><a id="comments"></a><div id="disqus_thread"></div><script>var disqus_shortname = 'yinwoods';
var disqus_identifier = '2018/06/02/IO模式和IO多路复用/';
var disqus_title = 'IO模式和IO多路复用';
var disqus_url = 'http://blog.yinwoods.work/2018/06/02/IO模式和IO多路复用/';
(function() {
    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
})();</script><script id="dsq-count-scr" src="//yinwoods.disqus.com/count.js" async></script></div></div></div></div><script src="/js/jquery.js"></script><script src="/js/jquery-migrate-1.2.1.min.js"></script><script src="/js/jquery.appear.js"></script></body></html>