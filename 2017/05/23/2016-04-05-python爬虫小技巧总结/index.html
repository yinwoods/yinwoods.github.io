<!DOCTYPE html><html lang="zh-CN"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta name="author" content="yinwoods,yinwoods#163.com"><title>python爬虫小技巧总结 · yinwoods</title><meta name="description" content="之前在码农网看过python的爬虫小技巧，但是我认为总结地不够全面，而且在这段编写爬虫的过程中，也形成了自己的套路～
特意在这里分享给大家，当然一方面也是以后忘记了留作参考。
1、基本网页抓取

包含伪装浏览器访问（解决403错误）

使用代理，避免长时间爬取被封本机IP

处理网页gzip压缩

"><meta name="keywords" content="Hexo,Linux,Python"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="renderer" content="webkit"><link rel="short icon" href="/images/favicon.png" type="image/x-icon"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/blog_basic.css"><link rel="stylesheet" href="/css/font-awesome.min.css"><link rel="alternate" type="application/atom+xml" title="ATOM 1.0" href="/atom.xml"></head><body><div class="sidebar animated fadeInDown"><div class="logo-title"><div class="title"><img src="/images/logo@2x.png" style="width:127px;"><h3 title=""><a href="/">yinwoods</a></h3><div class="description"><p>To Be A Better Man!😈</p></div></div></div><ul class="social-links"><li><a href="http://github.com/https://github.com/yinwoods"><i class="fa fa-github"></i></a></li></ul><div class="footer"><a target="_blank" href="/"><span>Theme by </span></a><a href="https://www.caicai.me"> CaiCai </a><span>&</span><a href="https://github.com/Ben02/hexo-theme-Anatole"> Ben</a><div class="by_farbox"><a href="https://hexo.io/zh-cn/" target="_blank">Proudly published with Hexo&#65281;</a></div></div></div><div class="main"><div class="page-top animated fadeInDown"><div class="nav"><li><a href="/">首页</a></li><li><a href="/about">关于</a></li><li><a href="/archives">归档</a></li><li><a href="/links">友链</a></li></div><div class="information"><div class="back_btn"><li><a onclick="window.history.go(-1)" class="fa fa-chevron-left"> </a></li></div><div class="avatar"><img src="/images/favicon.png"></div></div></div><div class="autopagerize_page_element"><div class="content"><div class="post-page"><div class="post animated fadeInDown"><div class="post-title"><h3><a>python爬虫小技巧总结</a></h3></div><div class="post-content"><p>之前在<a href="http://www.codeceo.com/article/python-spider-skills.html" target="_blank" rel="external">码农网</a>看过python的爬虫小技巧，但是我认为总结地不够全面，而且在这段编写爬虫的过程中，也形成了自己的套路～</p>
<p>特意在这里分享给大家，当然一方面也是以后忘记了留作参考。</p>
<h3 id="1、基本网页抓取"><a href="#1、基本网页抓取" class="headerlink" title="1、基本网页抓取"></a>1、基本网页抓取</h3><blockquote>
<ul>
<li><p>包含伪装浏览器访问（解决403错误）</p>
</li>
<li><p>使用代理，避免长时间爬取被封本机IP</p>
</li>
<li><p>处理网页gzip压缩</p>
</li>
<li><p>HTTPError异常处理</p>
</li>
</ul>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"><span class="comment">#获取url 对应 HTML 源码</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">getHtml</span><span class="params">(url)</span>:</span></div><div class="line">	<span class="comment">#伪装浏览器</span></div><div class="line">    header = dict(&#123; <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/48.0.2564.116 Chrome/48.0.2564.116 Safari/537.36'</span>,</div><div class="line">                    <span class="string">'Accept-encoding'</span>: <span class="string">'gzip'</span>,</div><div class="line">                    &#125;)</div><div class="line">    request = urllib.request.Request(url, headers=header)</div><div class="line"></div><div class="line">    </div><div class="line">    <span class="keyword">try</span>: </div><div class="line">    	<span class="comment">#使用代理：117.135.252.227:80</span></div><div class="line">        proxy_support = urllib.request.ProxyHandler(&#123;<span class="string">'http'</span>: <span class="string">'117.135.252.227:80'</span>&#125;)</div><div class="line">        opener = urllib.request.build_opener(proxy_support)</div><div class="line">        urllib.request.install_opener(opener)</div><div class="line"></div><div class="line">        page = urllib.request.urlopen(request)</div><div class="line"></div><div class="line">        <span class="comment">#print(page.headers.get('Content-Encoding')) 'gzip'</span></div><div class="line">        <span class="comment">#print(page.headers.get_content_charset()) 'utf8'</span></div><div class="line"></div><div class="line">        <span class="comment">#如果使用了gzip压缩</span></div><div class="line">        <span class="keyword">if</span> page.headers.get(<span class="string">'Content-Encoding'</span>) == <span class="string">'gzip'</span>:</div><div class="line">            <span class="keyword">return</span> zlib.decompress(page.read(), <span class="number">16</span>+zlib.MAX_WBITS).decode(<span class="string">'utf8'</span>)</div><div class="line">        <span class="keyword">else</span>: </div><div class="line">            <span class="keyword">return</span> page.read().decode(page.headers.get_content_charset())</div><div class="line"></div><div class="line">    <span class="keyword">except</span> urllib.request.HTTPError <span class="keyword">as</span> e:</div><div class="line">        print(<span class="string">'HTTPERROR: '</span>, str(e))</div><div class="line">    <span class="keyword">return</span> urllib.request.HTTPError</div></pre></td></tr></table></figure>
<h3 id="2、Mysql数据库操作"><a href="#2、Mysql数据库操作" class="headerlink" title="2、Mysql数据库操作"></a>2、Mysql数据库操作</h3><p>一般在类的构造函数<strong>init</strong>中完成数据库的连接，在析构函数中断开连接。</p>
<p>示例如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"><span class="keyword">import</span> mysql.connector</div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Example</span><span class="params">()</span>:</span></div><div class="line">	<span class="comment">#构造函数</span></div><div class="line">	<span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></div><div class="line">		self.conn = mysql.connector.connect(user=<span class="string">'root'</span>, password=<span class="string">'root'</span>, host=<span class="string">'localhost'</span>, database=<span class="string">'test'</span>)</div><div class="line">		self.cursor = self.conn.cursor(buffered=<span class="keyword">True</span>)</div><div class="line"></div><div class="line">	<span class="comment">#析构函数</span></div><div class="line">	<span class="function"><span class="keyword">def</span> <span class="title">__del__</span><span class="params">(self)</span>:</span></div><div class="line">		self.cursor.close()</div><div class="line">		self.conn.close()</div><div class="line"></div><div class="line">	<span class="comment">#数据库操作</span></div><div class="line">	<span class="comment">#查询table表中id=1的数据个数</span></div><div class="line">	<span class="function"><span class="keyword">def</span> <span class="title">doSomething</span><span class="params">(self)</span>:</span></div><div class="line">		query = <span class="string">'SELECT COUNT(*) FROM table WHERE id = %s'</span></div><div class="line">		data = (<span class="number">1</span>, )</div><div class="line"></div><div class="line">		<span class="comment">#执行查询</span></div><div class="line">		self.cursor.excute(query, data)</div><div class="line">		<span class="comment">#确保查询提交</span></div><div class="line">		self.conn.commit()</div></pre></td></tr></table></figure>
<h3 id="3、把json格式数据插入表中"><a href="#3、把json格式数据插入表中" class="headerlink" title="3、把json格式数据插入表中"></a>3、把json格式数据插入表中</h3><p>首先使用toJson()函数把我们要插入的数据项转为json格式，再使用jsonINTOMysql()函数将json格式数据插入mysql中。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">toJson</span><span class="params">(**kwargs)</span>:</span></div><div class="line">	<span class="keyword">return</span> kwargs</div><div class="line"></div><div class="line"><span class="comment">#把json格式的rowdict插入table中</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">jsonINToMysql</span><span class="params">(table, rowdict)</span>:</span></div><div class="line">    self.cursor.execute(<span class="string">'DESCRIBE %s'</span> % table)</div><div class="line">    allowedKeys = set(row[<span class="number">0</span>] <span class="keyword">for</span> row <span class="keyword">in</span> self.cursor.fetchall())</div><div class="line"></div><div class="line">    keys = allowedKeys.intersection(rowdict)</div><div class="line"></div><div class="line">    <span class="keyword">if</span> len(rowdict) &gt; len(keys):</div><div class="line">        unknownKeys = set(rowdict)-allowedKeys</div><div class="line">        print(sys.stderr, <span class="string">"skipping keys"</span>, <span class="string">","</span>.join(unknownKeys))</div><div class="line"></div><div class="line">    columns = <span class="string">","</span>.join(keys)</div><div class="line">    values_template = <span class="string">", "</span>.join([<span class="string">"%s"</span>]*len(keys))</div><div class="line"></div><div class="line">    sql = <span class="string">"INSERT INTO %s(%s) VALUES (%s)"</span> % (table, columns, values_template)</div><div class="line"></div><div class="line">    values = tuple(rowdict[key] <span class="keyword">for</span> key <span class="keyword">in</span> keys)</div><div class="line">    self.cursor.execute(sql, values)</div><div class="line">    self.conn.commit()</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">example</span><span class="params">()</span>:</span></div><div class="line">	<span class="comment">#假设数据表table中有id、name、sex三项</span></div><div class="line">	json = toJson(id=id, name=name, sex=sex)</div><div class="line">	jsonINTOMysql(<span class="string">'table'</span>, json)</div></pre></td></tr></table></figure>
<h3 id="4、对爬取数据的乱码进行解析"><a href="#4、对爬取数据的乱码进行解析" class="headerlink" title="4、对爬取数据的乱码进行解析"></a>4、对爬取数据的乱码进行解析</h3><p>有时我们需要爬取的是单独的json格式数据(请参考<a href="http://blog.yinwoods.com/coding/%E5%88%A9%E7%94%A8%E7%88%AC%E8%99%AB%E7%88%AC%E5%8F%96js%E7%94%9F%E6%88%90%E6%95%B0%E6%8D%AE.html" target="_blank" rel="external">利用爬虫爬取js生成数据</a>)，可能会发现json中的数据是经过编码的，例如我爬取汽车之家车辆的详细参数配置时，会发现json中的数据为：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">&#123;&quot;SIP_C_119&quot;:&quot;2645&quot;,&quot;SIP_C_250&quot;:&quot;%2d&quot;,&quot;SIP_C_306&quot;:&quot;%2d&quot;,&quot;SIP_T_LOGO&quot;:&quot;http://i1.itc.cn/20130624/83e_01580269_5a5f_1526_74cc_c6bf0064c28e_1.jpg&quot;,&quot;SIP_C_114&quot;:&quot;%2d%2d%2d&quot;,&quot;SIP_C_117&quot;:&quot;7005&quot;,&quot;SIP_C_305&quot;:&quot;%2d&quot;,&quot;SIP_C_304&quot;:&quot;%2d%2d%2d&quot;,&quot;SIP_C_118&quot;:&quot;2040&quot;,&quot;SIP_C_303&quot;:&quot;%u67f4%u6cb9%u673a&quot;,&quot;SIP_C_115&quot;:&quot;%u6574%u8f663%u5e74%2f6%u4e07%u516c%u91cc&quot;,&quot;SIP_C_116&quot;:&quot;%2d%2d%2d&quot;,&quot;model_engine_type&quot;:2,&quot;SIP_C_120&quot;:&quot;3935&quot;,&quot;overseas&quot;:false,&quot;SIP_T_PRICE&quot;:32.0,&quot;SIP_C_261&quot;:&quot;%u25cf&quot;,&quot;SIP_T_ID&quot;:127870,&quot;SIP_T_GEAR&quot;:&quot;M&quot;,&quot;SIP_C_124&quot;:&quot;%u5ba2%u8f66&quot;,&quot;SIP_C_125&quot;:&quot;2&quot;,&quot;SIP_C_126&quot;:&quot;10%2d23&quot;,&quot;SIP_C_127&quot;:&quot;90&quot;,&quot;SIP_C_170&quot;:&quot;%2d&quot;,&quot;SIP_C_329&quot;:&quot;120&quot;,&quot;SIP_C_171&quot;:&quot;%u673a%u68b0%u6db2%u538b%u52a9%u529b%u8f6c%u5411&quot;,&quot;SIP_C_322&quot;:&quot;%2d&quot;,&quot;SIP_T_MODELNAME&quot;:&quot;%u5b89%u51ef%u5ba2%u8f66%20%u5b9d%u65af%u901a&quot;,&quot;SIP_C_321&quot;:&quot;%2d&quot;,&quot;SIP_C_320&quot;:&quot;%u624b%u52a8&quot;,&quot;SIP_C_185&quot;:&quot;%u25cf&quot;,&quot;SIP_C_283&quot;:&quot;%u25cf&quot;,&quot;SIP_C_318&quot;:&quot;%u5364%u7d20&quot;,&quot;SIP_C_108&quot;:&quot;5%u6863%u624b%u52a8&quot;,&quot;SIP_C_317&quot;:&quot;%2d&quot;,&quot;SIP_C_285&quot;:&quot;%u25cf&quot;,&quot;SIP_C_314&quot;:&quot;%2d&quot;,&quot;SIP_C_104&quot;:&quot;%u6c5f%u6dee%u6c7d%u8f66&quot;,&quot;SIP_C_313&quot;:&quot;%2d&quot;,&quot;SIP_C_105&quot;:&quot;%u5176%u4ed6%u8f66%u578b&quot;,&quot;SIP_C_316&quot;:&quot;%2d&quot;,&quot;SIP_C_106&quot;:&quot;2%u95e810%2d23%u5ea7%u5ba2%u8f66&quot;,&quot;SIP_C_315&quot;:&quot;%2d&quot;,&quot;SIP_C_107&quot;:&quot;3%2e0T%20163%u9a6c%u529bL4&quot;,&quot;SIP_C_310&quot;:&quot;%2d&quot;,&quot;SIP_C_312&quot;:&quot;%2d&quot;,&quot;SIP_C_102&quot;:&quot;32%2e0%u4e07%u5143&quot;,&quot;SIP_C_103&quot;:&quot;32%2e0%7e32%2e0%u4e07%u5143&quot;,&quot;SIP_C_150&quot;:&quot;%u7f38%u5185%u76f4%u55b7&quot;,&quot;SIP_C_294&quot;:&quot;%2d%2d%2f%2d%2d%2f%2d%2d&quot;,&quot;SIP_C_297&quot;:&quot;163&quot;,&quot;SIP_C_291&quot;:&quot;%2d%2d%2d&quot;,&quot;SIP_C_151&quot;:&quot;%u94dd%u5408%u91d1&quot;,&quot;SIP_C_293&quot;:&quot;7005x2040x2645&quot;,&quot;SIP_C_152&quot;:&quot;%u94f8%u94c1&quot;,&quot;SIP_C_292&quot;:&quot;%2d%2d%2d&quot;,&quot;SIP_T_DISPL&quot;:3.0,&quot;SIP_C_158&quot;:&quot;%u624b%u52a8&quot;,&quot;SIP_C_157&quot;:&quot;5&quot;,&quot;SIP_C_156&quot;:&quot;5%u6863%u624b%u52a8&quot;,&quot;SIP_C_155&quot;:&quot;%u56fdIV&quot;,&quot;SIP_C_298&quot;:&quot;120%2f3800&quot;,&quot;SIP_C_299&quot;:&quot;362%2f1600%2d2200&quot;,&quot;SIP_C_159&quot;:&quot;%u4e2d%u7f6e%u540e%u9a71&quot;,&quot;SIP_C_224&quot;:&quot;%u771f%u76ae&quot;,&quot;SIP_C_160&quot;:&quot;%u9ea6%u5f17%u900a%u5f0f%u72ec%u7acb%u60ac%u6302&quot;,&quot;SIP_C_161&quot;:&quot;%u94a2%u677f%u5f39%u7c27%u7ed3%u6784&quot;,&quot;SIP_C_162&quot;:&quot;%u627f%u8f7d%u5f0f%u8f66%u8eab&quot;,&quot;SIP_C_163&quot;:&quot;7%2e00%20R16&quot;,&quot;SIP_C_164&quot;:&quot;7%2e00%20R16&quot;,&quot;SIP_C_165&quot;:&quot;%u94a2%u5236&quot;,&quot;nameDomain&quot;:&quot;4094&quot;,&quot;SIP_C_167&quot;:&quot;%u901a%u98ce%u76d8%u5f0f&quot;,&quot;SIP_C_166&quot;:&quot;%u5168%u5c3a%u5bf8%u5907%u80ce&quot;,&quot;SIP_C_169&quot;:&quot;%u624b%u5239%u5f0f%u5236%u52a8&quot;,&quot;SIP_C_168&quot;:&quot;%u9f13%u5f0f&quot;,&quot;SIP_T_MODELID&quot;:4094,&quot;SIP_T_STA&quot;:1,&quot;SIP_C_335&quot;:&quot;6%u4e07&quot;,&quot;SIP_C_333&quot;:&quot;1600&quot;,&quot;SIP_C_334&quot;:&quot;2200&quot;,&quot;SIP_C_332&quot;:&quot;362&quot;,&quot;SIP_T_YEAR&quot;:2014,&quot;SIP_C_330&quot;:&quot;3800&quot;,&quot;SIP_C_139&quot;:&quot;4&quot;,&quot;SIP_C_138&quot;:&quot;%u6da1%u8f6e%u589e%u538b&quot;,&quot;SIP_C_137&quot;:&quot;2968&quot;,&quot;SIP_C_136&quot;:&quot;3%2e0&quot;,&quot;SIP_C_135&quot;:&quot;NGD3%2e0%2dC3HA&quot;,&quot;SIP_C_134&quot;:&quot;3%2e0T%20163%u9a6c%u529bL4&quot;,&quot;SIP_C_249&quot;:&quot;0&quot;,&quot;SIP_C_140&quot;:&quot;%u76f4%u5217&quot;,&quot;SIP_C_141&quot;:&quot;4&quot;,&quot;SIP_C_347&quot;:&quot;%u5364%u7d20&quot;,&quot;SIP_C_142&quot;:&quot;%u53cc%u9876%u7f6e&quot;,&quot;brandNameDomain&quot;:&quot;ak-2171&quot;,&quot;SIP_C_149&quot;:&quot;%u67f4%u6cb9&quot;,&quot;SIP_C_148&quot;:&quot;40%2e0&quot;,&quot;SIP_T_NAME&quot;:&quot;3%2e0T%20VIP%u7248&quot;,&quot;SIP_C_241&quot;:&quot;%u25cf&quot;&#125;</div></pre></td></tr></table></figure>
<p>这种编码相信大家看着很熟悉，就像我们把包含中文的url地址复制粘贴下来的结果，那么我们该怎么对这种数据进行解码呢？</p>
<p>使用这种方式：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#对str先进行unquote url解码，再进行eval unicode解码</span></div><div class="line"><span class="comment">#处理数据时只需要我们把key-value对中的value依次作为参数传给deUnicode即可</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">deUnicode</span><span class="params">(str)</span>:</span></div><div class="line">    <span class="keyword">try</span>:</div><div class="line">        ans = eval(<span class="string">'"%s"'</span> % unquote(str).replace(<span class="string">'%'</span>, <span class="string">'\\'</span>))</div><div class="line">        <span class="keyword">return</span> ans</div><div class="line">    <span class="keyword">except</span> SyntaxError <span class="keyword">as</span> e:</div><div class="line">        <span class="keyword">return</span> str</div></pre></td></tr></table></figure>
<h3 id="5、requests通过post提交表单数据（一般用于模拟登录）"><a href="#5、requests通过post提交表单数据（一般用于模拟登录）" class="headerlink" title="5、requests通过post提交表单数据（一般用于模拟登录）"></a>5、requests通过post提交表单数据（一般用于模拟登录）</h3><p>requests的post实现依赖于维持一个session，也就是说在session存在期间，我们可以以登录的身份来获取其他需要登录后才能获取的页面源码。</p>
<p>简单使用如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"></div><div class="line">url = <span class="string">''</span></div><div class="line">datas = urllib.parse.urlencode(&#123;</div><div class="line">   <span class="string">'data-key'</span> : <span class="string">'data-value'</span></div><div class="line">&#125;)</div><div class="line"></div><div class="line">headers = dict(&#123;</div><div class="line">    <span class="string">'header-key'</span> : <span class="string">'header-value'</span></div><div class="line">&#125;)</div><div class="line"></div><div class="line">session = requests.session()</div><div class="line">session.post(url, datas, headers=headers)</div><div class="line"></div><div class="line">res = session.get(other url).text</div></pre></td></tr></table></figure>
</div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-sun-o"></i><span class="date">2017-05-23</span><i class="fa fa-tag"></i><a href="/categories/coding/" title="coding" class="tag">coding </a><a href="/tags/python-爬虫/" title="python, 爬虫" class="tag">python, 爬虫 </a></div></div></div></div><div class="share"><div class="evernote"><a href="javascript:(function(){EN_CLIP_HOST='http://www.evernote.com';try{var%20x=document.createElement('SCRIPT');x.type='text/javascript';x.src=EN_CLIP_HOST+'/public/bookmarkClipper.js?'+(new%20Date().getTime()/100000);document.getElementsByTagName('head')[0].appendChild(x);}catch(e){location.href=EN_CLIP_HOST+'/clip.action?url='+encodeURIComponent(location.href)+'&amp;title='+encodeURIComponent(document.title);}})();" ref="nofollow" target="_blank" class="fa fa-bookmark"></a></div><div class="weibo"><a href="javascript:void((function(s,d,e){try{}catch(e){}var f='http://service.weibo.com/share/share.php?',u=d.location.href,p=['url=',e(u),'&amp;title=',e(d.title),'&amp;appkey=2924220432'].join('');function a(){if(!window.open([f,p].join(''),'mb',['toolbar=0,status=0,resizable=1,width=620,height=450,left=',(s.width-620)/2,',top=',(s.height-450)/2].join('')))u.href=[f,p].join('');};if(/Firefox/.test(navigator.userAgent)){setTimeout(a,0)}else{a()}})(screen,document,encodeURIComponent));" class="fa fa-weibo"></a></div><div class="twitter"><a href="http://twitter.com/home?status=,http://blog.yinwoods.work/2017/05/23/2016-04-05-python爬虫小技巧总结/,yinwoods,python爬虫小技巧总结,;" class="fa fa-twitter"></a></div></div><div class="pagination"><ul class="clearfix"><li class="next pagbuttons"><a role="navigation" href="/2017/05/23/2016-05-31-python-challenge前十三关答案/" title="python challenge前十三关答案" class="btn">下一篇</a></li></ul></div></div></div></div></div><script src="/js/jquery.js"></script><script src="/js/jquery-migrate-1.2.1.min.js"></script><script src="/js/jquery.appear.js"></script></body></html>