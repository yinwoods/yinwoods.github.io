<!DOCTYPE html><html lang="zh-CN"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta name="author" content="yinwoods,yinwoods#163.com"><title>python爬虫requests登录解决422错误 · yinwoods</title><meta name="description" content="小伙伴崔崔今天要爬取北航ACT实验室的车联网的信息，已有账号密码。模拟登录使用的是python的requests.session().post(),通过chrome的network观察post的表单数据，发现有一个authenticity_token，这个数据是每次刷网页动态生成的，存放在页面hea"><meta name="keywords" content="Hexo,Linux,Python"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="renderer" content="webkit"><link rel="short icon" href="/images/favicon.png" type="image/x-icon"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/blog_basic.css"><link rel="stylesheet" href="/css/font-awesome.min.css"><link rel="alternate" type="application/atom+xml" title="ATOM 1.0" href="/atom.xml"></head><body><div class="sidebar animated fadeInDown"><div class="logo-title"><div class="title"><img src="/images/logo@2x.png" style="width:127px;"><h3 title=""><a href="/">yinwoods</a></h3><div class="description"><p>To Be A Better Man!😈</p></div></div></div><ul class="social-links"><li><a href="http://github.com/https://github.com/yinwoods"><i class="fa fa-github"></i></a></li></ul><div class="footer"><a target="_blank" href="/"><span>Theme by </span></a><a href="https://www.caicai.me"> CaiCai </a><span>&</span><a href="https://github.com/Ben02/hexo-theme-Anatole"> Ben</a><div class="by_farbox"><a href="https://hexo.io/zh-cn/" target="_blank">Proudly published with Hexo&#65281;</a></div></div></div><div class="main"><div class="page-top animated fadeInDown"><div class="nav"><li><a href="/">首页</a></li><li><a href="/about">关于</a></li><li><a href="/archives">归档</a></li><li><a href="/links">友链</a></li></div><div class="information"><div class="back_btn"><li><a onclick="window.history.go(-1)" class="fa fa-chevron-left"> </a></li></div><div class="avatar"><img src="/images/favicon.png"></div></div></div><div class="autopagerize_page_element"><div class="content"><div class="post-page"><div class="post animated fadeInDown"><div class="post-title"><h3><a>python爬虫requests登录解决422错误</a></h3></div><div class="post-content"><p>小伙伴<a href="http://blog.csdn.net/cumtcyf" target="_blank" rel="external">崔崔</a>今天要爬取<a href="http://ucar.act.buaa.edu.cn/users/sign_in" target="_blank" rel="external">北航ACT实验室的车联网</a>的信息，已有账号密码。模拟登录使用的是python的requests.session().post(),通过chrome的network观察post的表单数据，发现有一个<code>authenticity_token</code>，这个数据是每次刷网页动态生成的，存放在页面header的meta标签中，问题不大，直接用beautifulsoup获取就可以了。</p>
<p>问题出现在post之后，总是得到HTTP 422错误。通过查询了解到这里的422错误是指验证错误，可是token是即时获取的，其他信息也是完全按照表单要求填写，并且对提交数据进行了urlencode并使用<code>gbk</code>encode，实在是想不通原因。然后通过神奇的谷歌居然搜到了相同问题的博客。。。连代码都写得和我的惊人的相似。。。我都开始怀疑是不是和我爬的同一个网站了。。。</p>
<p>正确的爬取姿势是带着cookie验证，我猜这里的<code>authenticity_token</code>与cookie是相关联的，因为爬取时没带上cookie，所以无法验证成功。如果想要带上cookie只需使用<code>requests.Session()</code>来post即可。</p>
<p><a href="http://docs.python-requests.org/zh_CN/latest/user/advanced.html#advanced" target="_blank" rel="external">requests.Session()简介</a></p>
<p>简单介绍一下：</p>
<p>Session作为一个会话对象，会在同一个Session实例发出所有请求之间保存cookie。其实这里可以类比一下：当你登录淘宝后，短时间内访问淘宝的其他页面，不需要重新登录。</p>
<p>完整的代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#author : yinwoods</span></div><div class="line"><span class="keyword">import</span> urllib</div><div class="line"><span class="keyword">import</span> requests</div><div class="line"><span class="keyword">import</span> urllib.request</div><div class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></div><div class="line"></div><div class="line">    url = <span class="string">'http://ucar.act.buaa.edu.cn/users/sign_in'</span></div><div class="line"></div><div class="line"></div><div class="line">    headers = &#123;</div><div class="line">        <span class="string">'Accept'</span>: <span class="string">'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8'</span>,</div><div class="line">        <span class="string">'Accept-Encoding'</span>: <span class="string">'gzip,deflate'</span>,</div><div class="line">        <span class="string">'Accept-Language'</span>: <span class="string">'zh-CN,zh;q=0.8'</span>,</div><div class="line">        <span class="string">'Connection'</span>: <span class="string">'keep-alive'</span>,</div><div class="line">        <span class="string">'Content-Type'</span>: <span class="string">'application/x-www-form-urlencoded'</span>,</div><div class="line">        <span class="string">'Host'</span>: <span class="string">'ucar.act.buaa.edu.cn'</span>,</div><div class="line">        <span class="string">'Origin'</span>: <span class="string">'http://ucar.act.buaa.edu.cn'</span>,</div><div class="line">        <span class="string">'Referer'</span>: <span class="string">'http://ucar.act.buaa.edu.cn/stat'</span>,</div><div class="line">        <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0(X11;Linux x86_64) AppleWebKit/537.36(KHTML, like Gecko) Ubuntu Chromium/51.0.2704.79 Chrome/51.0.2704.79 Safari / 537.36'</span></div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">#先获取页面源码，提取token</span></div><div class="line">    session = requests.Session()</div><div class="line">    html = session.get(url, headers=headers).text</div><div class="line"></div><div class="line">    htmlDoc = BeautifulSoup(html, <span class="string">'html.parser'</span>)</div><div class="line">    token = htmlDoc.find_all(<span class="string">'meta'</span>)[<span class="number">-1</span>][<span class="string">'content'</span>]</div><div class="line"></div><div class="line">    print(token)</div><div class="line"></div><div class="line">    datas = urllib.parse.urlencode(&#123;</div><div class="line">        <span class="string">'utf8'</span>: <span class="string">'✓'</span>,</div><div class="line">        <span class="string">'authenticity_token'</span>: token,</div><div class="line">        <span class="string">'user[username]'</span>: username,</div><div class="line">        <span class="string">'user[password]'</span>: password,</div><div class="line">        <span class="string">'user[remember_me]'</span>: <span class="string">'1'</span>,</div><div class="line">        <span class="string">'commit'</span>: <span class="string">'登录'</span></div><div class="line">    &#125;).encode(<span class="string">'gbk'</span>)</div><div class="line"></div><div class="line">    requests.session().post()</div><div class="line"></div><div class="line">    print(datas)</div><div class="line"></div><div class="line">    print(session.post(url=url, params=datas, headers=headers))</div><div class="line"></div><div class="line">    res = session.get(<span class="string">'http://ucar.act.buaa.edu.cn/users/sign_in'</span>).text</div><div class="line">    print(res)</div><div class="line"></div><div class="line"></div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</div><div class="line">    main()</div></pre></td></tr></table></figure>
<p>打印页面后可以发现登录成功，状态码返回200。事后反思，意识到<code>token+cookie</code>可能这是一种比较通用的验证机制，自己不了解一方面是因为经验不足，另一方面可能就是之前爬的网站大都比较简单（是属于开放类门户网站），能够爬取成功并不代表自己的能力很高。</p>
<p>不过话又说回来自己想学的东西太多了。。。目前在看CSAPP，后面有时间再学习《HTTP权威指南》。</p>
</div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-sun-o"></i><span class="date">2017-05-23</span><i class="fa fa-tag"></i><a href="/categories/myshare/" title="myshare" class="tag">myshare </a><a href="/tags/python-爬虫/" title="python, 爬虫" class="tag">python, 爬虫 </a></div></div></div></div><div class="share"><div class="evernote"><a href="javascript:(function(){EN_CLIP_HOST='http://www.evernote.com';try{var%20x=document.createElement('SCRIPT');x.type='text/javascript';x.src=EN_CLIP_HOST+'/public/bookmarkClipper.js?'+(new%20Date().getTime()/100000);document.getElementsByTagName('head')[0].appendChild(x);}catch(e){location.href=EN_CLIP_HOST+'/clip.action?url='+encodeURIComponent(location.href)+'&amp;title='+encodeURIComponent(document.title);}})();" ref="nofollow" target="_blank" class="fa fa-bookmark"></a></div><div class="weibo"><a href="javascript:void((function(s,d,e){try{}catch(e){}var f='http://service.weibo.com/share/share.php?',u=d.location.href,p=['url=',e(u),'&amp;title=',e(d.title),'&amp;appkey=2924220432'].join('');function a(){if(!window.open([f,p].join(''),'mb',['toolbar=0,status=0,resizable=1,width=620,height=450,left=',(s.width-620)/2,',top=',(s.height-450)/2].join('')))u.href=[f,p].join('');};if(/Firefox/.test(navigator.userAgent)){setTimeout(a,0)}else{a()}})(screen,document,encodeURIComponent));" class="fa fa-weibo"></a></div><div class="twitter"><a href="http://twitter.com/home?status=,http://blog.yinwoods.work/2017/05/23/2016-07-27-python爬虫requests登录解决422错误/,yinwoods,python爬虫requests登录解决422错误,;" class="fa fa-twitter"></a></div></div><div class="pagination"><ul class="clearfix"><li class="pre pagbuttons"><a role="navigation" href="/2017/05/23/2016-07-07-python中的协程/" title="python中的协程" class="btn">上一篇</a></li><li class="next pagbuttons"><a role="navigation" href="/2017/05/23/2016-08-08-python中的context-manager/" title="python中的context manager" class="btn">下一篇</a></li></ul></div></div></div></div></div><script src="/js/jquery.js"></script><script src="/js/jquery-migrate-1.2.1.min.js"></script><script src="/js/jquery.appear.js"></script></body></html>