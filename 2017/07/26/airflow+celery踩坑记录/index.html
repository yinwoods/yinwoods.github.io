<!DOCTYPE html><html lang="zh-CN"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta name="author" content="yinwoods,yinwoods#163.com"><title>airflow + celery 踩坑记录 · yinwoods</title><meta name="description" content="初识 airflow其实早在去年就已经接触到 airflow 了，当时的需求是按小时拼接两份线上日志，而拼接操作必须依赖于两份日志的完整性。从这个需求出发，了解到了 airflow ，但迫于官方文档的晦涩难懂，再加上这个任务对 airflow 的需求不够强，就弃坑了；最后使用 python 脚本中一"><meta name="keywords" content="Hexo,Linux,Python"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="renderer" content="webkit"><link rel="short icon" href="/images/favicon.png" type="image/x-icon"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/blog_basic.css"><link rel="stylesheet" href="/css/font-awesome.min.css"><link rel="alternate" type="application/atom+xml" title="ATOM 1.0" href="/atom.xml"></head><body><div class="sidebar animated fadeInDown"><div class="logo-title"><div class="title"><img src="/images/logo@2x.png" style="width:127px;"><h3 title=""><a href="/">yinwoods</a></h3><div class="description"><p>To Be A Better Man!😈</p></div></div></div><ul class="social-links"><li><a href="http://weibo.com/yinwoods"><i class="fa fa-weibo"></i></a></li><li><a href="http://facebook.com/yinwoods"><i class="fa fa-facebook"></i></a></li><li><a href="http://github.com/yinwoods"><i class="fa fa-github"></i></a></li></ul><div class="footer"><a target="_blank" href="/"><span>Theme by </span></a><a href="https://www.caicai.me"> CaiCai </a><span>&</span><a href="https://github.com/Ben02/hexo-theme-Anatole"> Ben</a><div class="by_farbox"><a href="https://hexo.io/zh-cn/" target="_blank">Proudly published with Hexo&#65281;</a></div></div></div><div class="main"><div class="page-top animated fadeInDown"><div class="nav"><li><a href="/">首页</a></li><li><a href="/archives">归档</a></li><li><a href="/links">友链</a></li><li><a href="/about">关于</a></li></div><div class="information"><div class="back_btn"><li><a onclick="window.history.go(-1)" class="fa fa-chevron-left"> </a></li></div><div class="avatar"><img src="/images/favicon.png"></div></div></div><div class="autopagerize_page_element"><div class="content"><div class="post-page"><div class="post animated fadeInDown"><div class="post-title"><h3><a>airflow + celery 踩坑记录</a></h3></div><div class="post-content"><h3 id="初识-airflow"><a href="#初识-airflow" class="headerlink" title="初识 airflow"></a>初识 <a href="https://github.com/apache/incubator-airflow" target="_blank" rel="external">airflow</a></h3><p>其实早在去年就已经接触到 <a href="https://github.com/apache/incubator-airflow" target="_blank" rel="external">airflow</a> 了，当时的需求是按小时拼接两份线上日志，而拼接操作必须依赖于两份日志的完整性。从这个需求出发，了解到了 <a href="https://github.com/apache/incubator-airflow" target="_blank" rel="external">airflow</a> ，但迫于官方文档的晦涩难懂，再加上这个任务对 <a href="https://github.com/apache/incubator-airflow" target="_blank" rel="external">airflow</a> 的需求不够强，就弃坑了；最后使用 python 脚本中一个 while True 死循环 + time.sleep() 来解决问题(如果所依赖的日志没有完全写入，则 sleep 一段时间)。</p>
<h3 id="正式入坑"><a href="#正式入坑" class="headerlink" title="正式入坑"></a>正式入坑</h3><p>前几天 boss 布置了一个广告平台的统计任务，依赖倒也不复杂，但是考虑到未来平台的扩展性，还是需要一个能够很好的处理统计任务的工具的。自己也调研比较了一下<code>ETL(数据仓库)</code>这方面的工具，确实数 <a href="https://github.com/apache/incubator-airflow" target="_blank" rel="external">airflow</a> 功能最为强大，既然这样那就入坑吧。</p>
<h3 id="airflow-安装配置过程"><a href="#airflow-安装配置过程" class="headerlink" title="airflow 安装配置过程"></a><a href="https://github.com/apache/incubator-airflow" target="_blank" rel="external">airflow</a> 安装配置过程</h3><p>这里都是按照官网操作，具体如下:</p>
<p>1、设置 <a href="https://github.com/apache/incubator-airflow" target="_blank" rel="external">airflow</a> 项目路径，默认是用户主目录下 <a href="https://github.com/apache/incubator-airflow" target="_blank" rel="external">airflow</a> ，也可以显示用环境变量 <code>AIRFLOW_HOME</code> 指定;</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">export</span> AIRFLOW_HOME=~/airflow</div></pre></td></tr></table></figure>
<p>2、<a href="https://github.com/apache/incubator-airflow" target="_blank" rel="external">airflow</a> 安装，因为 <a href="https://github.com/apache/incubator-airflow" target="_blank" rel="external">airflow</a> 是基于 python 编写，因此可以直接利用 pip 安装，这里要注意的是 <a href="https://github.com/apache/incubator-airflow" target="_blank" rel="external">airflow</a> 还提供了使用其他软件的插件，例如 mysql、hdfs、hive 等工具，当然这些也可以在后续需要时再安装。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">pip3 install airflow</div><div class="line"></div><div class="line"><span class="comment"># 安装 [airflow](https://github.com/apache/incubator-airflow) hive 插件</span></div><div class="line">pip3 install <span class="string">"airflow[hive]"</span></div></pre></td></tr></table></figure>
<p>3、初始化 <a href="https://github.com/apache/incubator-airflow" target="_blank" rel="external">airflow</a> 相关数据库</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">airflow initdb</div></pre></td></tr></table></figure>
<p>4、启动 webserver 服务</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">airflow webserver</div></pre></td></tr></table></figure>
<p>至此，一个最基础的 <a href="https://github.com/apache/incubator-airflow" target="_blank" rel="external">airflow</a> 服务就启动了，下面说一说 <a href="https://github.com/apache/incubator-airflow" target="_blank" rel="external">airflow</a> 的配置。</p>
<h3 id="airflow-基础配置"><a href="#airflow-基础配置" class="headerlink" title="airflow 基础配置"></a><a href="https://github.com/apache/incubator-airflow" target="_blank" rel="external">airflow</a> 基础配置</h3><p><a href="https://github.com/apache/incubator-airflow" target="_blank" rel="external">airflow</a> 的配置文件保存在项目目录下，命名为 airflow.cfg ，通过文件内的注释也可以知道每个配置项的大致含义，这里简单说下常用的配置项。</p>
<h4 id="更改数据库"><a href="#更改数据库" class="headerlink" title="更改数据库"></a>更改数据库</h4><p><a href="https://github.com/apache/incubator-airflow" target="_blank" rel="external">airflow</a> 为了能够让用户快速使用选择了 sqllite 数据库，但在实际使用中，往往 mysql 更为广泛使用，若要使 <a href="https://github.com/apache/incubator-airflow" target="_blank" rel="external">airflow</a> 使用 mysql ，首先执行</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">pip3 install <span class="string">"airflow[mysql]"</span></div></pre></td></tr></table></figure>
<p>更改 airflow.cfg 中 <code>sql_alchemy_conn</code> 的值，通过变量名可知配置使用的是 <a href="https://www.sqlalchemy.org/" target="_blank" rel="external">sql_alchemy</a> 的数据库连接字符串，具体格式为：<code>mysql+pymysql://username:password@host:port/database</code>，当然这里 <a href="https://github.com/PyMySQL/PyMySQL" target="_blank" rel="external">pymysql</a> 可以根据自己喜好更换。</p>
<p>修改完配置文件后，需要执行 <code>airflow resetdb</code> 并重新启动 web 服务(<code>airflow webserver</code>)，数据库更换则生效。</p>
<h4 id="为web服务开启用户身份验证功能"><a href="#为web服务开启用户身份验证功能" class="headerlink" title="为web服务开启用户身份验证功能"></a>为web服务开启用户身份验证功能</h4><p><a href="https://github.com/apache/incubator-airflow" target="_blank" rel="external">airflow</a> 默认是无需登录即可访问使用的，而在实际生产环境中为了提高系统的安全性，需要开启用户身份验证功能，具体步骤如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">[webserver]</div><div class="line"><span class="comment"># 开启用户身份验证</span></div><div class="line">authenticate = True</div><div class="line"></div><div class="line"><span class="comment"># 根据用户显示dag列表(依赖于用户身份验证的开启)</span></div><div class="line">filter_by_owner = False</div></pre></td></tr></table></figure>
<p>这样就开启了用户身份验证的功能，但系统还没有默认用户，需要自行手动添加，有两种方式，一种是直接插入默认用户信息到数据库对应的 users 表中(不推荐);另一种则是通过 <a href="https://github.com/apache/incubator-airflow" target="_blank" rel="external">airflow</a> 提供的功能来添加，具体操作如下：</p>
<p>打开ipython，执行以下代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> airflow</div><div class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> airflow <span class="keyword">import</span> models, settings</div><div class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> airflow.contrib.auth.backends.password_auth <span class="keyword">import</span> PasswordUser</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>user = PasswordUser(models.User())</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>user.username = <span class="string">'new_user_name'</span></div><div class="line"><span class="meta">&gt;&gt;&gt; </span>user.email = <span class="string">'new_user_email@example.com'</span></div><div class="line"><span class="meta">&gt;&gt;&gt; </span>user.password = <span class="string">'set_the_password'</span></div><div class="line"><span class="meta">&gt;&gt;&gt; </span>session = settings.Session()</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>session.add(user)</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>session.commit()</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>session.close()</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>exit()</div></pre></td></tr></table></figure>
<p>重启 web 服务( <code>airflow webserver</code> )，刷新网址浏览器会自动跳转到用户登录页面。</p>
<h3 id="配置-airflow-Celery"><a href="#配置-airflow-Celery" class="headerlink" title="配置 airflow + Celery"></a>配置 <a href="https://github.com/apache/incubator-airflow" target="_blank" rel="external">airflow</a> + <a href="http://www.celeryproject.org/" target="_blank" rel="external">Celery</a></h3><p><a href="https://github.com/apache/incubator-airflow" target="_blank" rel="external">airflow</a> 提供了三种 Executor ，分别是 <code>SequentialExecutor</code>、<code>LocalExecutor</code> 以及 <code>CeleryExecutor</code>；<a href="https://github.com/apache/incubator-airflow" target="_blank" rel="external">airflow</a> 配置文件中，默认的执行方式是(<code>SequentialExecutor</code>)，这三者的特点如下：</p>
<ul>
<li><code>SequentialExecutor</code>: 单进程顺序执行，通常只用于测试</li>
<li><code>LocalExecutor</code>: 多进程本地执行，使用python的多进程库达到多进程执行目的</li>
<li><code>CeleryExecutor</code>: 使用<a href="http://www.celeryproject.org/" target="_blank" rel="external">Celery</a> 作为执行器，配置 <a href="http://www.celeryproject.org/" target="_blank" rel="external">Celery</a> 后可以利用集群分布式执行任务</li>
</ul>
<p>在这里我选用了<a href="http://www.celeryproject.org/" target="_blank" rel="external">Celery</a>，同样是为了 <a href="https://github.com/apache/incubator-airflow" target="_blank" rel="external">airflow</a> 未来的可扩展性。</p>
<p>官方文档中提到使用 <a href="http://www.celeryproject.org/" target="_blank" rel="external">Celery</a> 时，后端服务可以使用 <a href="https://www.rabbitmq.com/" target="_blank" rel="external">RabbitMQ</a> 或 <a href="https://redis.io/" target="_blank" rel="external">Redis</a> ，相对来说自己对 redis 熟悉一些，但据我所知 <a href="https://redis.io/" target="_blank" rel="external">Redis</a> 相对来说比较吃内存，因此在这里选用了 <a href="https://www.rabbitmq.com/" target="_blank" rel="external">RabbitMQ</a> 。具体配置如下：</p>
<h4 id="安装-RabbitMQ"><a href="#安装-RabbitMQ" class="headerlink" title="安装 RabbitMQ"></a>安装 <a href="https://www.rabbitmq.com/" target="_blank" rel="external">RabbitMQ</a></h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Ubuntu 17.04</span></div><div class="line">sudo apt install erlang rabbitmq-server</div></pre></td></tr></table></figure>
<h4 id="RabbitMQ-添加用户并设置密码"><a href="#RabbitMQ-添加用户并设置密码" class="headerlink" title="RabbitMQ 添加用户并设置密码"></a><a href="https://www.rabbitmq.com/" target="_blank" rel="external">RabbitMQ</a> 添加用户并设置密码</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Ubuntu 17.04</span></div><div class="line">sudo rabbitmqctl add_user airflow airflow</div><div class="line">sudo rabbitmqctl add_vhost airflow</div><div class="line">sudo rabbitmqctl set_user_tags airflow airflow</div><div class="line">sudo rabbitmqctl set_permissions -p airflow airflow <span class="string">".*"</span> <span class="string">".*"</span> <span class="string">".*"</span></div><div class="line">sudo rabbitmq-plugins <span class="built_in">enable</span> rabbitmq_management</div></pre></td></tr></table></figure>
<p>更改配置文件</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># transport://userid:password@hostname:port/virtual_host</span></div><div class="line">broker_url = amqp://ariflow:airflow@localhost:5672/airflow</div><div class="line">celery_result_backend = amqp://airflow:airflow@localhost:5672/airflow</div></pre></td></tr></table></figure>
<p>至此 <a href="https://github.com/apache/incubator-airflow" target="_blank" rel="external">airflow</a> + <a href="http://www.celeryproject.org/" target="_blank" rel="external">Celery</a> 配置完成，接下来说说如何启动服务</p>
<h3 id="启动-Airflow-Celery-服务"><a href="#启动-Airflow-Celery-服务" class="headerlink" title="启动 Airflow + Celery 服务"></a>启动 Airflow + Celery 服务</h3><p>一共有四个服务，分别是：</p>
<ul>
<li><code>airflow webserver</code> 服务</li>
<li><code>airflow flower</code> <a href="http://www.celeryproject.org/" target="_blank" rel="external">Celery</a> 管理界面</li>
<li><code>airflow worker</code> <a href="http://www.celeryproject.org/" target="_blank" rel="external">Celery</a> Worker</li>
<li><code>airflow scheduler</code> 调度器</li>
</ul>
<h4 id="启动-airflow-webserver-服务"><a href="#启动-airflow-webserver-服务" class="headerlink" title="启动 airflow webserver 服务"></a>启动 <code>airflow webserver</code> 服务</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">airflow webserver</div></pre></td></tr></table></figure>
<h4 id="启动airflow-flower"><a href="#启动airflow-flower" class="headerlink" title="启动airflow flower"></a>启动<a href="https://github.com/apache/incubator-airflow" target="_blank" rel="external">airflow</a> flower</h4><p><code>airflow flower</code> 是一个监控 <a href="http://www.celeryproject.org/" target="_blank" rel="external">Celery</a> 分布式队列的 web 服务，通过它可以看到 <a href="https://github.com/apache/incubator-airflow" target="_blank" rel="external">airflow</a> dag 中task 的执行状况。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">airflow flower</div></pre></td></tr></table></figure>
<h4 id="启动-airflow-worker"><a href="#启动-airflow-worker" class="headerlink" title="启动 airflow worker"></a>启动 <code>airflow worker</code></h4><p><a href="http://www.celeryproject.org/" target="_blank" rel="external">Celery</a> 的 worker，用于执行 dag 中具体的 task</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">airflow worker</div></pre></td></tr></table></figure>
<h4 id="启动-airflow-scheduler"><a href="#启动-airflow-scheduler" class="headerlink" title="启动 airflow scheduler"></a>启动 <code>airflow scheduler</code></h4><p><code>airflow scheduler</code> 用于启动调度器，完成对 dag 中 task 的调度。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">airflow scheduler</div></pre></td></tr></table></figure>
<h3 id="airflow-简单示例"><a href="#airflow-简单示例" class="headerlink" title="airflow 简单示例"></a><a href="https://github.com/apache/incubator-airflow" target="_blank" rel="external">airflow</a> 简单示例</h3><p>环境已经搭好，现在写个 dag 来测试一下 <a href="https://github.com/apache/incubator-airflow" target="_blank" rel="external">airflow</a> 吧。在具体的代码展现之前，先介绍一下上文已经出现多次的 dag 这个概念，dag 对于熟悉图论的同学一定不陌生，也即 <code>(Directed Acyclic Graph, DAG)</code> ，为什么叫有向无环图呢，因为任务之间的依赖关系就是一个 DAG ，如下图：<br><img src="/images/dag.png" alt="DAG">。</p>
<p><a href="https://github.com/apache/incubator-airflow" target="_blank" rel="external">airflow</a> 会默认读取 <a href="https://github.com/apache/incubator-airflow" target="_blank" rel="external">airflow</a> 目录下 dags 中的所有 python 文件作为 dag ，因此我们新建一个 dags 目录，并将下面的代码写入 <code>dags/test.py</code> 中，为了能够方便看到 dag 测试成功与否，在 test.py 里面设置了每次向 test 目录下的文件写入新内容。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> builtins <span class="keyword">import</span> range</div><div class="line"><span class="keyword">import</span> airflow</div><div class="line"><span class="keyword">from</span> airflow.operators.python_operator <span class="keyword">import</span> PythonOperator</div><div class="line"><span class="keyword">from</span> airflow.models <span class="keyword">import</span> DAG</div><div class="line"></div><div class="line"><span class="keyword">from</span> pprint <span class="keyword">import</span> pprint</div><div class="line"></div><div class="line">args = &#123;</div><div class="line">    <span class="string">'owner'</span>: <span class="string">'yinwoods'</span>,</div><div class="line">    <span class="string">'start_date'</span>: airflow.utils.dates.datetime(<span class="number">2017</span>, <span class="number">7</span>, <span class="number">27</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>)</div><div class="line">&#125;</div><div class="line"></div><div class="line">dag = DAG(</div><div class="line">    dag_id=<span class="string">'yinwoods'</span>, default_args=args,</div><div class="line">    schedule_interval=<span class="string">'0 1 * * *'</span>)</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">my_write_function</span><span class="params">(random_base)</span>:</span></div><div class="line">    <span class="string">"""This is a function that will run within the DAG execution"""</span></div><div class="line">    <span class="keyword">with</span> open(<span class="string">'~/airflow/test/'</span> + random_base, <span class="string">'a'</span>) <span class="keyword">as</span> f:</div><div class="line">        f.write(random_base[<span class="number">-1</span>] + <span class="string">'\n'</span>)</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">print_context</span><span class="params">(ds, **kwargs)</span>:</span></div><div class="line">    pprint(kwargs)</div><div class="line">    print(ds)</div><div class="line">    <span class="keyword">return</span> <span class="string">'Whatever you return gets printed in the logs'</span></div><div class="line"></div><div class="line"></div><div class="line">run_this = PythonOperator(</div><div class="line">    task_id=<span class="string">'print_the_context'</span>,</div><div class="line">    provide_context=<span class="keyword">True</span>,</div><div class="line">    python_callable=print_context,</div><div class="line">    op_kwargs=&#123;<span class="string">'test'</span>: <span class="string">'test'</span>&#125;,</div><div class="line">    dag=dag)</div><div class="line"></div><div class="line"><span class="comment"># Generate 10 sleeping tasks, sleeping from 0 to 9 seconds respectively</span></div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>):</div><div class="line">    task = PythonOperator(</div><div class="line">        task_id=<span class="string">'print_for_'</span> + str(i),</div><div class="line">        python_callable=my_write_function,</div><div class="line">        op_kwargs=&#123;<span class="string">'random_base'</span>: <span class="string">'file_'</span> + str(i)&#125;,</div><div class="line">        dag=dag)</div><div class="line"></div><div class="line">    task.set_upstream(run_this)</div></pre></td></tr></table></figure>
<p>以上代码保存后，执行 <code>python test.py</code> 即将该 dag 导入 <a href="https://github.com/apache/incubator-airflow" target="_blank" rel="external">airflow</a> 中，之后可以选用 <code>airflow test</code> 或 <code>airflow backfill</code> 测试，这里就不再讲述具体用法。</p>
<p>启动 dag 时既可以使用 <code>airflow run dag_id task_id execution_date</code> ，也可以使用 web 界面的执行按钮执行。但需要注意的是，在启动之前需要 <code>airflow unpause dag_id</code> 或在 web 界面开启 dag 对应的按钮。</p>
<p>接下来就可以看到执行状态以及结果了。另外下面提供了另一份示例代码，注意观察这份代码中定义任务间依赖关系的语句:)，个人认为这样的语句能够更直观表明任务之间的关系。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</div><div class="line"><span class="keyword">from</span> [airflow](https://github.com/apache/incubator-airflow) <span class="keyword">import</span> DAG</div><div class="line"><span class="keyword">from</span> airflow.operators.dummy_operator <span class="keyword">import</span> DummyOperator</div><div class="line"><span class="keyword">from</span> airflow.operators.python_operator <span class="keyword">import</span> PythonOperator</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">print_hello</span><span class="params">()</span>:</span></div><div class="line">    <span class="keyword">return</span> <span class="string">'Hello world!'</span></div><div class="line"></div><div class="line">dag = DAG(<span class="string">'hello_world'</span>, description=<span class="string">'Simple tutorial DAG'</span>,</div><div class="line">          schedule_interval=<span class="string">'0 12 * * *'</span>,</div><div class="line">          start_date=datetime(<span class="number">2017</span>, <span class="number">3</span>, <span class="number">20</span>),</div><div class="line">          catchup=<span class="keyword">False</span>)</div><div class="line"></div><div class="line">dummy_operator = DummyOperator(task_id=<span class="string">'dummy_task'</span>, retries=<span class="number">3</span>, dag=dag)</div><div class="line"></div><div class="line">hello_operator = PythonOperator(task_id=<span class="string">'hello_task'</span>,</div><div class="line">                                python_callable=print_hello, dag=dag)</div><div class="line"></div><div class="line">dummy_operator &gt;&gt; hello_operator</div></pre></td></tr></table></figure>
<p>如果执行 dag 后，发现 dag 中部分 task 一直处于 queue 的状态，可以查看 <code>airflow scheduler</code> 的执行状态，如果是挂掉了，且重启后又挂掉可以参考下面的解决方法。</p>
<h3 id="改源码解决-airflow-scheduler-中断-bug"><a href="#改源码解决-airflow-scheduler-中断-bug" class="headerlink" title="改源码解决 airflow scheduler 中断 bug"></a>改源码解决 <code>airflow scheduler</code> 中断 bug</h3><p>我在使用 <a href="https://github.com/apache/incubator-airflow" target="_blank" rel="external">airflow</a>  的过程中，产生了 <code>airflow scheduler</code> 启动后执行片刻即被断开连接的情况，通过谷歌搜索，找到了以下修改 <a href="https://github.com/apache/incubator-airflow" target="_blank" rel="external">airflow</a> 源码的解决方法，至于这个中断bug的具体原因尚不清楚。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div></pre></td><td class="code"><pre><div class="line">--- /usr/local/lib/python3<span class="number">.4</span>/dist-packages/airflow/jobs.py.orig	<span class="number">2017</span><span class="number">-02</span><span class="number">-16</span> <span class="number">11</span>:<span class="number">58</span>:<span class="number">55.057991344</span> +<span class="number">0000</span></div><div class="line">+++ /usr/local/lib/python3<span class="number">.4</span>/dist-packages/airflow/jobs.py	<span class="number">2017</span><span class="number">-02</span><span class="number">-16</span> <span class="number">11</span>:<span class="number">57</span>:<span class="number">07.060060262</span> +<span class="number">0000</span></div><div class="line"><span class="meta">@@ -1371,6 +1371,8 @@</span></div><div class="line">         last_stat_print_time = datetime(<span class="number">2000</span>, <span class="number">1</span>, <span class="number">1</span>)</div><div class="line">         <span class="comment"># Last time that self.heartbeat() was called.</span></div><div class="line">         last_self_heartbeat_time = datetime.now()</div><div class="line">+        <span class="comment"># Last time that self.executor.heartbeat() was called.</span></div><div class="line">+        last_executor_heartbeat_time = datetime.now()</div><div class="line">         <span class="comment"># Last time that the DAG dir was traversed to look for files</span></div><div class="line">         last_dag_dir_refresh_time = datetime.now()</div><div class="line"></div><div class="line"><span class="meta">@@ -1436,9 +1438,14 @@</span></div><div class="line">                 self._execute_task_instances(simple_dag_bag,</div><div class="line">                                              (State.SCHEDULED,))</div><div class="line"></div><div class="line">-            <span class="comment"># Call hearbeats</span></div><div class="line">-            self.logger.info(<span class="string">"Heartbeating the executor"</span>)</div><div class="line">-            self.executor.heartbeat()</div><div class="line">+            <span class="comment"># Heartbeat the executor periodically</span></div><div class="line">+            time_since_last_heartbeat = (datetime.now() -</div><div class="line">+                                         last_executor_heartbeat_time).total_seconds()</div><div class="line">+            <span class="keyword">if</span> time_since_last_heartbeat &gt; self.heartrate:</div><div class="line">+                self.logger.info(<span class="string">"Heartbeating the executor"</span>)</div><div class="line">+                <span class="keyword">try</span>: self.executor.heartbeat()</div><div class="line">+                <span class="keyword">except</span> ConnectionResetError: <span class="keyword">pass</span>  <span class="comment"># RabbitMQ sometimes resets the socket connection</span></div><div class="line">+                last_executor_heartbeat_time = datetime.now()</div><div class="line"></div><div class="line">             <span class="comment"># Process events from the executor</span></div><div class="line">             self._process_executor_events()</div></pre></td></tr></table></figure>
<p><a href="https://github.com/apache/incubator-airflow" target="_blank" rel="external">airflow</a> 的介绍与使用就先写到这里，如果读者有与我类似或相同的问题，欢迎评论区探讨。</p>
<h3 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h3><ul>
<li><a href="https://airflow.incubator.apache.org/" target="_blank" rel="external">Airflow 官方文档</a></li>
<li><a href="http://morefreeze.github.io/2016/12/airflow.html" target="_blank" rel="external">Airflow 简明指南</a></li>
<li><a href="http://blog.genesino.com/2016/05/airflow/#%E9%85%8D%E7%BD%AEceleryexecutor-rabbitmq%E6%94%AF%E6%8C%81" target="_blank" rel="external">Airflow Useage</a></li>
<li><a href="https://issues.apache.org/jira/browse/AIRFLOW-342" target="_blank" rel="external">Exception in <a href="https://github.com/apache/incubator-airflow" target="_blank" rel="external">airflow</a> scheduler: Connection reset by peer</a></li>
</ul>
</div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-sun-o"></i><span class="date">2017-07-26</span><i class="fa fa-comment-o"></i><a href="/2017/07/26/airflow+celery踩坑记录/#comments">评论</a><i class="fa fa-tag"></i><a href="/categories/coding/" title="coding" class="tag">coding </a><a href="/tags/python-airflow-celery/" title="python, airflow, celery" class="tag">python, airflow, celery </a></div></div></div></div><div class="share"><div class="evernote"><a href="javascript:(function(){EN_CLIP_HOST='http://www.evernote.com';try{var%20x=document.createElement('SCRIPT');x.type='text/javascript';x.src=EN_CLIP_HOST+'/public/bookmarkClipper.js?'+(new%20Date().getTime()/100000);document.getElementsByTagName('head')[0].appendChild(x);}catch(e){location.href=EN_CLIP_HOST+'/clip.action?url='+encodeURIComponent(location.href)+'&amp;title='+encodeURIComponent(document.title);}})();" ref="nofollow" target="_blank" class="fa fa-bookmark"></a></div><div class="weibo"><a href="javascript:void((function(s,d,e){try{}catch(e){}var f='http://service.weibo.com/share/share.php?',u=d.location.href,p=['url=',e(u),'&amp;title=',e(d.title),'&amp;appkey=2924220432'].join('');function a(){if(!window.open([f,p].join(''),'mb',['toolbar=0,status=0,resizable=1,width=620,height=450,left=',(s.width-620)/2,',top=',(s.height-450)/2].join('')))u.href=[f,p].join('');};if(/Firefox/.test(navigator.userAgent)){setTimeout(a,0)}else{a()}})(screen,document,encodeURIComponent));" class="fa fa-weibo"></a></div><div class="twitter"><a href="http://twitter.com/home?status=,http://blog.yinwoods.work/2017/07/26/airflow+celery踩坑记录/,yinwoods,airflow + celery 踩坑记录,;" class="fa fa-twitter"></a></div></div><div class="pagination"><ul class="clearfix"><li class="pre pagbuttons"><a role="navigation" href="/2017/08/02/druid内存占用过多问题排查/" title="druid内存占用过多问题排查" class="btn">上一篇</a></li><li class="next pagbuttons"><a role="navigation" href="/2017/07/25/fluent-python-读书笔记/" title="《Fluent Python》读书笔记" class="btn">下一篇</a></li></ul></div><a id="comments"></a><div id="disqus_thread"></div><script>var disqus_shortname = 'yinwoods';
var disqus_identifier = '2017/07/26/airflow+celery踩坑记录/';
var disqus_title = 'airflow + celery 踩坑记录';
var disqus_url = 'http://blog.yinwoods.work/2017/07/26/airflow+celery踩坑记录/';
(function() {
    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
})();</script><script id="dsq-count-scr" src="//yinwoods.disqus.com/count.js" async></script></div></div></div></div><script src="/js/jquery.js"></script><script src="/js/jquery-migrate-1.2.1.min.js"></script><script src="/js/jquery.appear.js"></script></body></html>