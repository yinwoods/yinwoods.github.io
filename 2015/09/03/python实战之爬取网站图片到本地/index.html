<!DOCTYPE html><html lang="zh-CN"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta name="author" content="yinwoods,yinwoods#163.com"><title>python实战之爬取网站图片到本地 · yinwoods</title><meta name="description" content="下面是一个python小程序，用来获取对应网址上的图片，并保存到本地D://imgs_from_yinwoods/目录下（linux系统会在当前目录下生成对应文件夹）
123456789101112131415161718192021222324252627282930313233343536373"><meta name="keywords" content="Hexo,Linux,Python"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="renderer" content="webkit"><link rel="short icon" href="/images/favicon.png" type="image/x-icon"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/blog_basic.css"><link rel="stylesheet" href="/css/font-awesome.min.css"><link rel="alternate" type="application/atom+xml" title="ATOM 1.0" href="/atom.xml"></head><body><div class="sidebar animated fadeInDown"><div class="logo-title"><div class="title"><img src="/images/logo@2x.png" style="width:127px;"><h3 title=""><a href="/">yinwoods</a></h3><div class="description"><p>To Be A Better Man!😈</p></div></div></div><ul class="social-links"><li><a href="http://weibo.com/http://weibo.com/3090938041"><i class="fa fa-weibo"></i></a></li><li><a href="http://facebook.com/https://www.facebook.com/yinwoods"><i class="fa fa-facebook"></i></a></li><li><a href="http://github.com/https://github.com/yinwoods"><i class="fa fa-github"></i></a></li></ul><div class="footer"><a target="_blank" href="/"><span>Theme by </span></a><a href="https://www.caicai.me"> CaiCai </a><span>&</span><a href="https://github.com/Ben02/hexo-theme-Anatole"> Ben</a><div class="by_farbox"><a href="https://hexo.io/zh-cn/" target="_blank">Proudly published with Hexo&#65281;</a></div></div></div><div class="main"><div class="page-top animated fadeInDown"><div class="nav"><li><a href="/">首页</a></li><li><a href="/archives">归档</a></li><li><a href="/links">友链</a></li><li><a href="/about">关于</a></li></div><div class="information"><div class="back_btn"><li><a onclick="window.history.go(-1)" class="fa fa-chevron-left"> </a></li></div><div class="avatar"><img src="/images/favicon.png"></div></div></div><div class="autopagerize_page_element"><div class="content"><div class="post-page"><div class="post animated fadeInDown"><div class="post-title"><h3><a>python实战之爬取网站图片到本地</a></h3></div><div class="post-content"><p>下面是一个<code>python</code>小程序，用来获取对应网址上的图片，并保存到本地<code>D://imgs_from_yinwoods/</code>目录下（<strong>linux系统会在当前目录下生成对应文件夹</strong>）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#coding=utf-8</span></div><div class="line"><span class="keyword">import</span> re</div><div class="line"><span class="keyword">import</span> os</div><div class="line"><span class="keyword">import</span> urllib</div><div class="line"><span class="keyword">import</span> urllib.request</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">getHtml</span><span class="params">(url)</span>:</span>	<span class="comment">#用来获取给定url对应页面源码</span></div><div class="line">    page = urllib.request.urlopen(url)</div><div class="line">    html = page.read()</div><div class="line">    <span class="keyword">return</span> html</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">getImg</span><span class="params">(htmls)</span>:</span>	<span class="comment">#获取htmls集合中含有的图片</span></div><div class="line">    print(<span class="string">"I'm trying to get sexy images......"</span>)</div><div class="line">    print(<span class="string">"The images I'll get will be placed in dir D://imgs_from_yinwoods"</span>)</div><div class="line">    reg = <span class="string">r'src="(.+?\.jpg)"'</span>	<span class="comment">#正则表达式匹配图片url</span></div><div class="line">    imgre = re.compile(reg)</div><div class="line">    x = <span class="number">0</span></div><div class="line">    cnt = <span class="number">0</span></div><div class="line">    imglist = []</div><div class="line">    <span class="keyword">for</span> cnt <span class="keyword">in</span> range(<span class="number">0</span>, <span class="number">4</span>):	<span class="comment">#存取4个页面集合的图片url地址</span></div><div class="line">        imglist.append(re.findall(imgre, str(htmls[cnt].decode(<span class="string">'utf-8'</span>))))</div><div class="line">    path = os.path.join(<span class="string">"D:/"</span>, <span class="string">"imgs_from_yinwoods"</span>)	<span class="comment">#设置文件存放文件夹</span></div><div class="line">    os.makedirs(path)	<span class="comment">#创建文件夹</span></div><div class="line">    <span class="keyword">for</span> imgurl <span class="keyword">in</span> imglist:</div><div class="line">        <span class="keyword">for</span> url <span class="keyword">in</span> imgurl:</div><div class="line">            print(url)</div><div class="line">            url = <span class="string">"http://hiowner.com/"</span>+url</div><div class="line">            print(url)</div><div class="line">            urllib.request.urlretrieve(url, <span class="string">'D://imgs_from_yinwoods/%s.jpg'</span> % x)</div><div class="line">            x += <span class="number">1</span></div><div class="line">            print(<span class="string">"I've got %d images"</span> % x)</div><div class="line">            <span class="keyword">if</span> x &gt; <span class="number">99</span>:</div><div class="line">                <span class="keyword">return</span></div><div class="line"></div><div class="line">html1 = getHtml(<span class="string">"http://hiowner.com/users"</span>)</div><div class="line">html2 = getHtml(<span class="string">"http://hiowner.com/users/page/2"</span>)</div><div class="line">html3 = getHtml(<span class="string">"http://hiowner.com/users/page/3"</span>)</div><div class="line">html4 = getHtml(<span class="string">"http://hiowner.com/users/page/4"</span>)</div><div class="line"></div><div class="line">htmls = []</div><div class="line">htmls.append(html1)</div><div class="line">htmls.append(html2)</div><div class="line">htmls.append(html3)</div><div class="line">htmls.append(html4)</div><div class="line"></div><div class="line">getImg(htmls)</div></pre></td></tr></table></figure>
<p>最近重新看这份代码，发现写的非常不好，而且试了下运行的话会报403错误。原因是该网站不允许爬虫直接读取页面内容。</p>
<p>那我们所要做的就是给爬虫穿上伪装的外衣就好了。在尝试读取网页内容的时候为头信息添加User-Agent即可。</p>
<p>还要注意的是这里不能用<code>urllib.request.urlretrieve()</code>，原因是无法赋予User-Agent信息，所以我采用了读取文件源码再写到本地的方法。</p>
<p>另外我又加了多线程机制提高爬取效率。</p>
<p>代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#coding=utf-8</span></div><div class="line"><span class="keyword">import</span> re</div><div class="line"><span class="keyword">import</span> os</div><div class="line"><span class="keyword">import</span> time</div><div class="line"><span class="keyword">import</span> threading</div><div class="line"><span class="keyword">import</span> urllib</div><div class="line"><span class="keyword">import</span> urllib.request</div><div class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">MM_Crawler</span>:</span></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getHtmlContents</span><span class="params">(self, url)</span>:</span>   <span class="comment">#用来获取给定url对应页面源码</span></div><div class="line"></div><div class="line">        headers = &#123;</div><div class="line">            <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/48.0.2564.116 Chrome/48.0.2564.116 Safari/537.36'</span>,</div><div class="line">        &#125;</div><div class="line">        headers = dict(headers)</div><div class="line">        req = urllib.request.Request(url, headers=headers)</div><div class="line">        response = urllib.request.urlopen(req)</div><div class="line"></div><div class="line">        html = response.read()</div><div class="line">        <span class="keyword">return</span> html</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getImg</span><span class="params">(self, html, id)</span>:</span>  <span class="comment">#获取htmls集合中含有的图片</span></div><div class="line">        print(<span class="string">"I'm trying to get sexy images......"</span>)</div><div class="line">        print(<span class="string">"The images I'll get will be placed in dir D://imgs_from_yinwoods"</span>)</div><div class="line"></div><div class="line">        html_Doc = BeautifulSoup(html)</div><div class="line"></div><div class="line">        divLists = html_Doc.find_all(<span class="string">"div"</span>, <span class="string">"panel-body"</span>)</div><div class="line"></div><div class="line">        urllib.request.urlretrieve()</div><div class="line"></div><div class="line">        imgNum = <span class="number">0</span></div><div class="line"></div><div class="line">        dirName = <span class="string">"page-"</span> + str(id)</div><div class="line">        <span class="keyword">if</span> os.path.exists(dirName):</div><div class="line">            print(<span class="string">"文件夹已存在！"</span>)</div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            os.mkdir(dirName)</div><div class="line"></div><div class="line">        <span class="keyword">for</span> divItem <span class="keyword">in</span> divLists:</div><div class="line">            link = divItem.find(<span class="string">'a'</span>)</div><div class="line">            <span class="keyword">if</span> link != <span class="keyword">None</span>:</div><div class="line">                imgLink = <span class="string">"http://hiowner.com/"</span> + link.find(<span class="string">'img'</span>)[<span class="string">'src'</span>]</div><div class="line">                imgNum += <span class="number">1</span></div><div class="line"></div><div class="line">                img = self.getHtmlContents(imgLink)</div><div class="line"></div><div class="line">                regx = re.compile(<span class="string">'(\/page\/\d)'</span>)</div><div class="line"></div><div class="line">                fileName = dirName + <span class="string">'/%s.jpg'</span> % imgNum</div><div class="line">                <span class="keyword">with</span> open(fileName, <span class="string">'wb'</span>) <span class="keyword">as</span> file:</div><div class="line">                    <span class="keyword">if</span> os.path.isfile(fileName):</div><div class="line">                        print(fileName + <span class="string">"  已存在！"</span>)</div><div class="line">                    <span class="keyword">else</span>:</div><div class="line">                        file.write(img)</div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line">mmcrawler = MM_Crawler()</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">tsk1</span><span class="params">(pageNum)</span>:</span></div><div class="line">    url = <span class="string">"http://hiowner.com/users/page/"</span> + str(pageNum)</div><div class="line">    mmcrawler.getImg(mmcrawler.getHtmlContents(url).decode(<span class="string">'utf8'</span>), pageNum)</div><div class="line">    time.sleep(<span class="number">1</span>)</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">createMultiThread</span><span class="params">(threadNum)</span>:</span></div><div class="line">    threads = []</div><div class="line">    <span class="keyword">for</span> num <span class="keyword">in</span> range(threadNum):</div><div class="line">        threads.append(threading.Thread(target=tsk1, args=str(num+<span class="number">1</span>)))</div><div class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> threads:</div><div class="line">        t.start()</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></div><div class="line"></div><div class="line">    createMultiThread(<span class="number">5</span>)</div><div class="line"></div><div class="line"></div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</div><div class="line">    main()</div></pre></td></tr></table></figure>
</div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-sun-o"></i><span class="date">2015-09-03</span><i class="fa fa-comment-o"></i><a href="/2015/09/03/python实战之爬取网站图片到本地/#comments">评论</a><i class="fa fa-tag"></i><a href="/categories/coding/" title="coding" class="tag">coding </a><a href="/tags/python-爬虫/" title="python, 爬虫" class="tag">python, 爬虫 </a></div></div></div></div><div class="share"><div class="evernote"><a href="javascript:(function(){EN_CLIP_HOST='http://www.evernote.com';try{var%20x=document.createElement('SCRIPT');x.type='text/javascript';x.src=EN_CLIP_HOST+'/public/bookmarkClipper.js?'+(new%20Date().getTime()/100000);document.getElementsByTagName('head')[0].appendChild(x);}catch(e){location.href=EN_CLIP_HOST+'/clip.action?url='+encodeURIComponent(location.href)+'&amp;title='+encodeURIComponent(document.title);}})();" ref="nofollow" target="_blank" class="fa fa-bookmark"></a></div><div class="weibo"><a href="javascript:void((function(s,d,e){try{}catch(e){}var f='http://service.weibo.com/share/share.php?',u=d.location.href,p=['url=',e(u),'&amp;title=',e(d.title),'&amp;appkey=2924220432'].join('');function a(){if(!window.open([f,p].join(''),'mb',['toolbar=0,status=0,resizable=1,width=620,height=450,left=',(s.width-620)/2,',top=',(s.height-450)/2].join('')))u.href=[f,p].join('');};if(/Firefox/.test(navigator.userAgent)){setTimeout(a,0)}else{a()}})(screen,document,encodeURIComponent));" class="fa fa-weibo"></a></div><div class="twitter"><a href="http://twitter.com/home?status=,http://blog.yinwoods.work/2015/09/03/python实战之爬取网站图片到本地/,yinwoods,python实战之爬取网站图片到本地,;" class="fa fa-twitter"></a></div></div><div class="pagination"><ul class="clearfix"><li class="pre pagbuttons"><a role="navigation" href="/2015/09/03/python爬虫基础教程/" title="python爬虫基础教程" class="btn">上一篇</a></li><li class="next pagbuttons"><a role="navigation" href="/2015/08/29/jekyll博客标签云tag-cloud实现/" title="Jekyll博客标签云（tag_cloud）实现" class="btn">下一篇</a></li></ul></div><a id="comments"></a><div id="disqus_thread"></div><script>var disqus_shortname = 'yinwoods';
var disqus_identifier = '2015/09/03/python实战之爬取网站图片到本地/';
var disqus_title = 'python实战之爬取网站图片到本地';
var disqus_url = 'http://blog.yinwoods.work/2015/09/03/python实战之爬取网站图片到本地/';
(function() {
    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
})();</script><script id="dsq-count-scr" src="//yinwoods.disqus.com/count.js" async></script></div></div></div></div><script src="/js/jquery.js"></script><script src="/js/jquery-migrate-1.2.1.min.js"></script><script src="/js/jquery.appear.js"></script></body></html>