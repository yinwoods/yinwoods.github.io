<!DOCTYPE html><html lang="zh-CN"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta name="author" content="yinwoods,yinwoods#163.com"><title>python爬虫基础教程 · yinwoods</title><meta name="description" content="爬虫首先上爬虫的定义：网络爬虫是一种自动获取网页内容的程序，是搜索引擎的重要组成部分。
嗯，按照我的理解就是爬虫程序就是能够提取网页中信息的程序
我也是这两天才开始学爬虫，这篇教程参考了网上的很多资源，希望能给有需要的人以帮助。
在各位看官开始学习之前想向大家介绍几篇文章，请大家认真阅读，这样上手p"><meta name="keywords" content="Hexo,Linux,Python"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="renderer" content="webkit"><link rel="short icon" href="/images/favicon.png" type="image/x-icon"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/blog_basic.css"><link rel="stylesheet" href="/css/font-awesome.min.css"><link rel="alternate" type="application/atom+xml" title="ATOM 1.0" href="/atom.xml"></head><body><div class="sidebar animated fadeInDown"><div class="logo-title"><div class="title"><img src="/images/logo@2x.png" style="width:127px;"><h3 title=""><a href="/">yinwoods</a></h3><div class="description"><p>To Be A Better Man!😈</p></div></div></div><ul class="social-links"><li><a href="http://weibo.com/http://weibo.com/yinwoods"><i class="fa fa-weibo"></i></a></li><li><a href="http://facebook.com/https://www.facebook.com/yinwoods"><i class="fa fa-facebook"></i></a></li><li><a href="http://github.com/https://github.com/yinwoods"><i class="fa fa-github"></i></a></li></ul><div class="footer"><a target="_blank" href="/"><span>Theme by </span></a><a href="https://www.caicai.me"> CaiCai </a><span>&</span><a href="https://github.com/Ben02/hexo-theme-Anatole"> Ben</a><div class="by_farbox"><a href="https://hexo.io/zh-cn/" target="_blank">Proudly published with Hexo&#65281;</a></div></div></div><div class="main"><div class="page-top animated fadeInDown"><div class="nav"><li><a href="/">首页</a></li><li><a href="/archives">归档</a></li><li><a href="/links">友链</a></li><li><a href="/about">关于</a></li></div><div class="information"><div class="back_btn"><li><a onclick="window.history.go(-1)" class="fa fa-chevron-left"> </a></li></div><div class="avatar"><img src="/images/favicon.png"></div></div></div><div class="autopagerize_page_element"><div class="content"><div class="post-page"><div class="post animated fadeInDown"><div class="post-title"><h3><a>python爬虫基础教程</a></h3></div><div class="post-content"><h3 id="爬虫"><a href="#爬虫" class="headerlink" title="爬虫"></a>爬虫</h3><p>首先上爬虫的定义：<code>网络爬虫是一种自动获取网页内容的程序，是搜索引擎的重要组成部分。</code></p>
<p>嗯，按照我的理解就是爬虫程序就是能够提取网页中信息的程序</p>
<p>我也是这两天才开始学爬虫，这篇教程参考了网上的很多资源，希望能给有需要的人以帮助。</p>
<p>在各位看官开始学习之前想向大家介绍几篇文章，请大家认真阅读，这样上手<code>python</code>爬虫就会事半功倍了。</p>
<blockquote>
<p>1、<a href="http://www.zhihu.com/question/20899988" target="_blank" rel="external">如何入门Python爬虫 — from 知乎</a></p>
<p>2、<a href="http://www.zhihu.com/question/21358581" target="_blank" rel="external">你是如何开始能写python爬虫？ — from 知乎</a></p>
<p>3、<a href="http://blog.jobbole.com/77821/" target="_blank" rel="external">零基础自学用Python 3开发网络爬虫</a></p>
</blockquote>
<p>我很大程度上是按照上面介绍的第三篇博客入门<code>python</code>爬虫的。</p>
<h3 id="Python介绍"><a href="#Python介绍" class="headerlink" title="Python介绍"></a>Python介绍</h3><p><code>Python</code>（英国发音：<code>/ˈpaɪθən/</code> 美国发音：<code>/ˈpaɪθɑːn/</code>），是一种面向对象、直译式的计算机程序语言，具有近二十年的发展历史。它包含了一组功能完备的标准库，能够轻松完成很多常见的任务。它的语法简单，与其它大多数程序设计语言使用大括号不一样，它使用缩进来定义语句块。<a href="https://zh.wikipedia.org/wiki/Python" target="_blank" rel="external">— 来自于维基百科</a></p>
<p>另外该篇博客适用于有高等语法基础（不需要必须是<code>python</code>）的朋友，没有语法基础的朋友可以去<a href="http://www.imooc.com/learn/177" target="_blank" rel="external">慕课网</a>或<a href="https://www.codecademy.com/en/tracks/python" target="_blank" rel="external">codecademy</a>学习下</p>
<h3 id="工欲善其事必先利其器"><a href="#工欲善其事必先利其器" class="headerlink" title="工欲善其事必先利其器"></a>工欲善其事必先利其器</h3><p>在学习<code>python</code>的过程中，不得不面临<code>python 2.+</code>或<code>python 3.+</code>的选择，个人觉得既然是出于学习的目的，当然要学习新知识，因此我选择了<code>python 3.4</code>。</p>
<p>个人使用体会：<code>python3.+</code>在<code>python2.+</code>的基础上对包又进行了一些整合，语法略有些变化，可能因为现在我涉及的层面还比较浅，并未感觉两个版本之间有太大的不同。</p>
<p>可以通过<a href="https://www.python.org/" target="_blank" rel="external">官网</a>安装<code>python 3.4</code>；附<a href="https://www.python.org/" target="_blank" rel="external"><code>python</code>官方文档</a></p>
<p>我们现在的目标是实现一个可以从一个链接开始爬取所有相关链接的爬虫</p>
<p>思路：</p>
<blockquote>
<ul>
<li><p>1、从给定链接开始，维持一个待爬取队列，以及一个已访问链接集合</p>
</li>
<li><p>2、每次从队列中弹出一条链接并打开，对于该链接对应页面，用正则表达式匹配页面内所有的链接，</p>
</li>
<li><p>3、对这些链接进行判断，如果已经被爬虫爬过，则跳过，否则加入待爬取队列</p>
</li>
<li><p>4、重复2,3步，直到队列为空，说明所有链接均已被爬取</p>
</li>
</ul>
</blockquote>
<p>话不多说，下面通过8个程序来学习<code>python</code>爬虫吧</p>
<h4 id="python教程-1-1"><a href="#python教程-1-1" class="headerlink" title="python教程-1.1"></a>python教程-1.1</h4><p>python中使用<code>#</code>注释，多行注释使用快捷键<code>Alt+3</code>，消除多行注释使用快捷键<code>Alt+4</code></p>
<p>下面这个小程序的功能是打开一个网页并读取网页源码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"><span class="keyword">import</span> urllib</div><div class="line"><span class="keyword">import</span> urllib.request</div><div class="line"></div><div class="line">url = <span class="string">"http://baidu.com"</span></div><div class="line"></div><div class="line">html = urllib.request.urlopen(url)	<span class="comment">#打开url链接</span></div><div class="line"></div><div class="line">html = html.read().decode(<span class="string">'utf-8'</span>)	<span class="comment">#以utf-8编码格式对所读取页面进行解码</span></div><div class="line"></div><div class="line">print(html)		<span class="comment">#打印网页源码</span></div></pre></td></tr></table></figure>
<h4 id="python教程-1-2"><a href="#python教程-1-2" class="headerlink" title="python教程-1.2"></a>python教程-1.2</h4><p>使用下面这个程序实现python中我们需要的队列<br>deque的相关内容可参见C++或java中deque的定义</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"><span class="comment">#利用deque模拟Queue</span></div><div class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> deque</div><div class="line"></div><div class="line">queue = deque([<span class="string">"Eric"</span>, <span class="string">"John"</span>, <span class="string">"Michael"</span>])</div><div class="line">queue.append(<span class="string">"Terry"</span>)</div><div class="line">queue.append(<span class="string">"Graham"</span>)</div><div class="line">print(queue.popleft())</div><div class="line">print(queue.popleft())</div><div class="line">print(queue)</div></pre></td></tr></table></figure>
<h4 id="python教程-1-3"><a href="#python教程-1-3" class="headerlink" title="python教程-1.3"></a>python教程-1.3</h4><p>下面这个小程序是为了演示<code>set</code>功能，类似于数学中集合的定义，每个元素具有唯一性。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#演示set功能</span></div><div class="line">basket = &#123;<span class="string">'apple'</span>, <span class="string">'orange'</span>, <span class="string">'apple'</span>, <span class="string">'pear'</span>, <span class="string">'orange'</span>, <span class="string">'banana'</span>&#125;</div><div class="line">print(basket)</div><div class="line"></div><div class="line">print(<span class="string">'orange'</span> <span class="keyword">in</span> basket)</div><div class="line"></div><div class="line">print(<span class="string">'crabgrass'</span> <span class="keyword">in</span> basket)</div><div class="line"></div><div class="line">a = set(<span class="string">'abracadabra'</span>)</div><div class="line">b = set(<span class="string">'alacazam'</span>)</div><div class="line"></div><div class="line">print(a)</div><div class="line">print(a-b)</div><div class="line">print(a|b)</div><div class="line">print(a&amp;b)</div><div class="line">print(a^b)</div></pre></td></tr></table></figure>
<h4 id="python教程-1-4"><a href="#python教程-1-4" class="headerlink" title="python教程-1.4"></a>python教程-1.4</h4><p>程序演示python中正则表达式应用</p>
<p><code>re.match(pattern, string, flags=0)</code>实现按照<code>pattern</code>的模式匹配<code>string</code>，<code>flags</code>是附加标志位；</p>
<p>同理<code>re.search(pattern, string, flags=0)</code>实现搜索功能 ；</p>
<p><code>re.sub(pattern, string, flags=0)</code>实现替换功能。</p>
<p><code>re.match()</code>与<code>re.search()</code>区别在于</p>
<blockquote>
<ul>
<li><p>如果<code>re.match()</code>在匹配字符串开始的过程中失败就会终止匹配</p>
</li>
<li><p><code>re.search()</code>则会从字符串开始到结尾尝试匹配</p>
</li>
</ul>
</blockquote>
<p>有不懂或者遗忘正则表达式的朋友请点这里：</p>
<blockquote>
<ul>
<li><p>1、<a href="http://blog.yinwoods.com/coding/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E5%AD%A6%E4%B9%A0.html" target="_blank" rel="external">正则表达式教程</a></p>
</li>
<li><p>2、<a href="http://blog.jobbole.com/75188/" target="_blank" rel="external"><code>python</code>正则表达式学习</a></p>
</li>
</ul>
</blockquote>
<p>flag含义:</p>
<blockquote>
<p>1、 <code>re.I</code> 大小写不敏感</p>
<p>2、 <code>re.L</code> 本地化识别匹配</p>
<p>3、 <code>re.M</code> 多行匹配</p>
<p>4、 <code>re.S</code> 使.能够匹配换行符</p>
<p>5、 <code>re.U</code> 根据Unicode解析字符</p>
</blockquote>
<p>另外也可以使用<code>re.compile(pattern).findall(string)</code>来查找所有匹配，会返回所有匹配结果，并且结果保存在<code>列表</code>中（后面会有具体的栗子）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"><span class="comment">#re.match(pattern, string, flags=0)</span></div><div class="line"><span class="keyword">import</span> re</div><div class="line"></div><div class="line">line = <span class="string">"Cats are smarter than dogs"</span></div><div class="line"></div><div class="line">matchObj = re.match(<span class="string">r'(.*) are (.*?) .*'</span>, line, re.M|re.I)</div><div class="line"></div><div class="line"><span class="keyword">if</span> matchObj:</div><div class="line">    print(matchObj.group())</div><div class="line">    print(matchObj.group(<span class="number">1</span>))</div><div class="line">    print(matchObj.group(<span class="number">2</span>))</div><div class="line"><span class="keyword">else</span>:</div><div class="line">    print(<span class="string">"No match!!"</span>)</div><div class="line"></div><div class="line"><span class="comment">#演示python中正则表达式搜索应用</span></div><div class="line"><span class="comment">#re.search(pattern, string, flags=0)</span></div><div class="line">matchObj = re.search(<span class="string">r'(.*) are (.*?) .*'</span>, line, re.M|re.I)</div><div class="line"><span class="keyword">if</span> matchObj:</div><div class="line">    print(matchObj.group())</div><div class="line">    print(matchObj.group(<span class="number">1</span>))</div><div class="line">    print(matchObj.group(<span class="number">2</span>))</div><div class="line"><span class="keyword">else</span>:</div><div class="line">    print(<span class="string">"No match!!"</span>)</div><div class="line"></div><div class="line"><span class="comment">#演示python中正则表达式替换应用</span></div><div class="line"><span class="comment">#re.sub(pattern, repl, string, max=0)</span></div><div class="line">phone = <span class="string">"2004-959-559 # This is Phone Number"</span></div><div class="line"></div><div class="line">num = re.sub(<span class="string">r'#.*$'</span>, <span class="string">""</span>, phone)</div><div class="line">print(<span class="string">"Phone Num : "</span>, num)</div><div class="line"></div><div class="line">num = re.sub(<span class="string">r'\D'</span>, <span class="string">""</span>, phone)</div><div class="line">print(<span class="string">"Phone Num : "</span>, num)</div></pre></td></tr></table></figure>
<h4 id="python教程-1-5"><a href="#python教程-1-5" class="headerlink" title="python教程-1.5"></a>python教程-1.5</h4><p>目标的实现：下面的程序即实现了我们开始要求的功能，当然想把所有链接都爬取是需要时间的。。。当你觉得不需要再爬的时候可以中断程序</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"><span class="comment">#简单爬虫</span></div><div class="line"><span class="keyword">import</span> re</div><div class="line"><span class="keyword">import</span> urllib.request</div><div class="line"><span class="keyword">import</span> urllib</div><div class="line"></div><div class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> deque</div><div class="line"></div><div class="line">queue = deque()</div><div class="line">visited = set()</div><div class="line"></div><div class="line">url = <span class="string">"http://www.baidu.com"</span></div><div class="line"></div><div class="line">queue.append(url)</div><div class="line">cnt = <span class="number">0</span></div><div class="line"></div><div class="line"><span class="keyword">while</span> queue:	<span class="comment">#当队列不为空</span></div><div class="line">    url = queue.popleft()</div><div class="line">    visited |= &#123;url&#125;	<span class="comment">#加入visited集合中</span></div><div class="line">    print(<span class="string">'I\'v got :'</span> + str(cnt))</div><div class="line">    print(<span class="string">'I\'m getting '</span> + url)</div><div class="line">    cnt += <span class="number">1</span>;</div><div class="line">    urlop = urllib.request.urlopen(url)</div><div class="line">    <span class="keyword">if</span> <span class="string">'html'</span> <span class="keyword">not</span> <span class="keyword">in</span> urlop.getheader(<span class="string">'Content-Type'</span>):	<span class="comment">#避免爬取非网页url的链接，比如文件地址</span></div><div class="line">        <span class="keyword">continue</span></div><div class="line">    <span class="keyword">try</span>:</div><div class="line">        data = urlop.read().decode(<span class="string">'utf-8'</span>)	<span class="comment">#过滤掉不能正确读取的页面，避免程序异常中断</span></div><div class="line">    <span class="keyword">except</span>:</div><div class="line">        <span class="keyword">continue</span></div><div class="line"></div><div class="line">    linkre = re.compile(<span class="string">'href=\"(.+?)\"'</span>)</div><div class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> linkre.findall(data):</div><div class="line">        <span class="keyword">if</span> <span class="string">'http'</span> <span class="keyword">in</span> x <span class="keyword">and</span> x <span class="keyword">not</span> <span class="keyword">in</span> visited:	<span class="comment">#找出匹配后未访问过的链接</span></div><div class="line">            queue.append(x)</div><div class="line">            print(<span class="string">'appending ---&gt; '</span> + x)</div></pre></td></tr></table></figure>
<p>以上就是该篇博客所有内容了，如有未尽兴的朋友，请移步：</p>
<blockquote>
<p>1、<a href="http://blog.yinwoods.com/coding/python%E5%AE%9E%E6%88%98%E4%B9%8B%E7%88%AC%E5%8F%96%E7%BD%91%E7%AB%99%E5%9B%BE%E7%89%87%E5%88%B0%E6%9C%AC%E5%9C%B0.html" target="_blank" rel="external">python实战之爬取网站图片到本地</a></p>
<p>2、<a href="http://blog.yinwoods.com/coding/python%E5%AE%9E%E6%88%98%E4%B9%8B%E9%83%91%E5%B7%9E%E5%A4%A7%E5%AD%A6GPA%E8%AE%A1%E7%AE%97%E5%99%A8.html" target="_blank" rel="external">python实战之郑州大学GPA计算器</a></p>
</blockquote>
</div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-sun-o"></i><span class="date">2015-09-03</span><i class="fa fa-comment-o"></i><a href="/2015/09/03/python爬虫基础教程/#comments">评论</a><i class="fa fa-tag"></i><a href="/categories/coding/" title="coding" class="tag">coding </a><a href="/tags/python-爬虫/" title="python, 爬虫" class="tag">python, 爬虫 </a></div></div></div></div><div class="share"><div class="evernote"><a href="javascript:(function(){EN_CLIP_HOST='http://www.evernote.com';try{var%20x=document.createElement('SCRIPT');x.type='text/javascript';x.src=EN_CLIP_HOST+'/public/bookmarkClipper.js?'+(new%20Date().getTime()/100000);document.getElementsByTagName('head')[0].appendChild(x);}catch(e){location.href=EN_CLIP_HOST+'/clip.action?url='+encodeURIComponent(location.href)+'&amp;title='+encodeURIComponent(document.title);}})();" ref="nofollow" target="_blank" class="fa fa-bookmark"></a></div><div class="weibo"><a href="javascript:void((function(s,d,e){try{}catch(e){}var f='http://service.weibo.com/share/share.php?',u=d.location.href,p=['url=',e(u),'&amp;title=',e(d.title),'&amp;appkey=2924220432'].join('');function a(){if(!window.open([f,p].join(''),'mb',['toolbar=0,status=0,resizable=1,width=620,height=450,left=',(s.width-620)/2,',top=',(s.height-450)/2].join('')))u.href=[f,p].join('');};if(/Firefox/.test(navigator.userAgent)){setTimeout(a,0)}else{a()}})(screen,document,encodeURIComponent));" class="fa fa-weibo"></a></div><div class="twitter"><a href="http://twitter.com/home?status=,http://blog.yinwoods.work/2015/09/03/python爬虫基础教程/,yinwoods,python爬虫基础教程,;" class="fa fa-twitter"></a></div></div><div class="pagination"><ul class="clearfix"><li class="pre pagbuttons"><a role="navigation" href="/2015/09/03/python实战之爬取网站图片到本地/" title="python实战之爬取网站图片到本地" class="btn">上一篇</a></li><li class="next pagbuttons"><a role="navigation" href="/2015/08/29/jekyll博客标签云tag-cloud实现/" title="Jekyll博客标签云（tag_cloud）实现" class="btn">下一篇</a></li></ul></div><a id="comments"></a><div id="disqus_thread"></div><script>var disqus_shortname = 'yinwoods';
var disqus_identifier = '2015/09/03/python爬虫基础教程/';
var disqus_title = 'python爬虫基础教程';
var disqus_url = 'http://blog.yinwoods.work/2015/09/03/python爬虫基础教程/';
(function() {
    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
})();</script><script id="dsq-count-scr" src="//yinwoods.disqus.com/count.js" async></script></div></div></div></div><script src="/js/jquery.js"></script><script src="/js/jquery-migrate-1.2.1.min.js"></script><script src="/js/jquery.appear.js"></script></body></html>